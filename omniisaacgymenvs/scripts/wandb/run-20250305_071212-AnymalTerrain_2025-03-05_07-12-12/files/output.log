
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /media/isaac/Daten/azhar_ws/OmniIsaacGymEnvs/omniisaacgymenvs/runs
Actor MLP: Actor(
  (priv_encoder): Sequential(
    (0): Linear(in_features=28, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=20, bias=True)
    (3): ELU(alpha=1.0)
  )
  (history_encoder): StateHistoryEncoder(
    (activation_fn): ELU(alpha=1.0)
    (encoder): Sequential(
      (0): Linear(in_features=48, out_features=30, bias=True)
      (1): ELU(alpha=1.0)
    )
    (conv_layers): Sequential(
      (0): Conv1d(30, 20, kernel_size=(4,), stride=(2,))
      (1): ELU(alpha=1.0)
      (2): Conv1d(20, 10, kernel_size=(2,), stride=(1,))
      (3): ELU(alpha=1.0)
      (4): Flatten(start_dim=1, end_dim=-1)
    )
    (linear_output): Sequential(
      (0): Linear(in_features=30, out_features=20, bias=True)
      (1): ELU(alpha=1.0)
    )
  )
  (actor_backbone): Sequential(
    (0): Linear(in_features=68, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (actor_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=12, bias=True)
    (5): Tanh()
  )
)
Critic MLP: Critic(
  (critic_backbone): Sequential(
    (0): Linear(in_features=76, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (critic_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
)
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ActorCritic                              12
â”œâ”€Actor: 1-1                             --
â”‚    â””â”€Sequential: 2-1                   --
â”‚    â”‚    â””â”€Linear: 3-1                  1,856
â”‚    â”‚    â””â”€ELU: 3-2                     --
â”‚    â”‚    â””â”€Linear: 3-3                  1,300
â”‚    â”‚    â””â”€ELU: 3-4                     --
â”‚    â””â”€StateHistoryEncoder: 2-2          --
â”‚    â”‚    â””â”€ELU: 3-5                     --
â”‚    â”‚    â””â”€Sequential: 3-6              1,470
â”‚    â”‚    â””â”€Sequential: 3-7              2,830
â”‚    â”‚    â””â”€Sequential: 3-8              620
â”‚    â””â”€Sequential: 2-3                   --
â”‚    â”‚    â””â”€Linear: 3-9                  8,832
â”‚    â”‚    â””â”€ELU: 3-10                    --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-11                 16,512
â”‚    â”‚    â””â”€ELU: 3-12                    --
â”‚    â”‚    â””â”€Linear: 3-13                 16,512
â”‚    â”‚    â””â”€ELU: 3-14                    --
â”‚    â”‚    â””â”€Linear: 3-15                 1,548
â”‚    â”‚    â””â”€Tanh: 3-16                   --
â”œâ”€Critic: 1-2                            --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-17                 9,856
â”‚    â”‚    â””â”€ELU: 3-18                    --
â”‚    â””â”€Sequential: 2-6                   --
â”‚    â”‚    â””â”€Linear: 3-19                 16,512
â”‚    â”‚    â””â”€ELU: 3-20                    --
â”‚    â”‚    â””â”€Linear: 3-21                 16,512
â”‚    â”‚    â””â”€ELU: 3-22                    --
â”‚    â”‚    â””â”€Linear: 3-23                 129
=================================================================
Total params: 94,501
Trainable params: 94,501
Non-trainable params: 0
=================================================================
[2025-03-05 07:12:14] Running RL reset
################################################################################
                     [1m Learning iteration 0/1000000 
                       Computation: 46 steps/s (collection: 1.552s, learning 0.163s)
               Value function loss: 0.0000
                    Surrogate loss: 0.0000
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.93
     action noise std distribution: [0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0, 0.800000011920929, 1.0, 1.0]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80
                    Iteration time: 1.71s
                        Total time: 1.71s
                               ETA: 1714322.8s
################################################################################
                     [1m Learning iteration 1/1000000 
                       Computation: 72 steps/s (collection: 0.982s, learning 0.128s)
               Value function loss: 0.0015
                    Surrogate loss: 1184.7043
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.94
     action noise std distribution: [0.803685188293457, 1.0036247968673706, 1.0028941631317139, 0.80314701795578, 1.0011868476867676, 1.0036630630493164, 0.8024265766143799, 1.0026628971099854, 1.0034964084625244, 0.8025586605072021, 1.0037331581115723, 1.003521203994751]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160
                    Iteration time: 1.11s
                        Total time: 2.83s
                               ETA: 1412563.1s
[34m[1mwandb[39m[22m: [33mWARNING[39m Step cannot be set when using syncing with tensorboard. Please log your step values as a metric such as 'global_step'
################################################################################
                     [1m Learning iteration 2/1000000 
                       Computation: 74 steps/s (collection: 0.970s, learning 0.099s)
               Value function loss: 0.0016
                    Surrogate loss: 161.7944
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.94
     action noise std distribution: [0.8056681752204895, 1.0064237117767334, 1.0053461790084839, 0.8070158362388611, 1.0029819011688232, 1.0069737434387207, 0.805841326713562, 1.0052250623703003, 1.0064055919647217, 0.8054917454719543, 1.0066710710525513, 1.006752610206604]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 240
                    Iteration time: 1.07s
                        Total time: 3.89s
                               ETA: 1297971.1s
################################################################################
                     [1m Learning iteration 3/1000000 
                       Computation: 72 steps/s (collection: 1.006s, learning 0.100s)
               Value function loss: 0.0013
                    Surrogate loss: 1029.0461
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.94
     action noise std distribution: [0.8086822032928467, 1.0098729133605957, 1.0085827112197876, 0.8112063407897949, 1.0054640769958496, 1.0100969076156616, 0.8099537491798401, 1.0083225965499878, 1.00969660282135, 0.8085583448410034, 1.0088410377502441, 1.0107465982437134]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 320
                    Iteration time: 1.11s
                        Total time: 5.00s
                               ETA: 1249852.8s
################################################################################
                     [1m Learning iteration 4/1000000 
                       Computation: 73 steps/s (collection: 0.993s, learning 0.099s)
               Value function loss: 0.0024
                    Surrogate loss: 520.9282
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.95
     action noise std distribution: [0.8122398853302002, 1.013627290725708, 1.0117957592010498, 0.8145022988319397, 1.0082378387451172, 1.012682318687439, 0.8132472038269043, 1.0110762119293213, 1.0125977993011475, 0.8104364275932312, 1.0119491815567017, 1.0139048099517822]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 400
                    Iteration time: 1.09s
                        Total time: 6.09s
                               ETA: 1218199.1s
################################################################################
                     [1m Learning iteration 5/1000000 
                       Computation: 69 steps/s (collection: 1.050s, learning 0.099s)
               Value function loss: 0.0011
                    Surrogate loss: 236.5204
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.95
     action noise std distribution: [0.8150068521499634, 1.013994812965393, 1.016183614730835, 0.8184190988540649, 1.0118478536605835, 1.016400694847107, 0.8154701590538025, 1.0142492055892944, 1.0165175199508667, 0.8124241828918457, 1.0142464637756348, 1.0172652006149292]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 480
                    Iteration time: 1.15s
                        Total time: 7.24s
                               ETA: 1206625.7s
################################################################################
                     [1m Learning iteration 6/1000000 
                       Computation: 75 steps/s (collection: 0.962s, learning 0.099s)
               Value function loss: 0.0004
                    Surrogate loss: 22.7692
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.95
     action noise std distribution: [0.8161452412605286, 1.015496015548706, 1.0208114385604858, 0.8200923800468445, 1.0152571201324463, 1.0195388793945312, 0.8179712295532227, 1.0172475576400757, 1.0173367261886597, 0.8139801025390625, 1.0169644355773926, 1.0200139284133911]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 560
                    Iteration time: 1.06s
                        Total time: 8.30s
                               ETA: 1185794.0s
################################################################################
                     [1m Learning iteration 7/1000000 
                       Computation: 73 steps/s (collection: 0.989s, learning 0.107s)
               Value function loss: 0.0006
                    Surrogate loss: 179.0413
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.95
     action noise std distribution: [0.8183272480964661, 1.0174529552459717, 1.0235507488250732, 0.8225706219673157, 1.0173484086990356, 1.022278904914856, 0.8204898238182068, 1.0197030305862427, 1.0175652503967285, 0.8171013593673706, 1.0203315019607544, 1.023459792137146]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 640
                    Iteration time: 1.10s
                        Total time: 9.40s
                               ETA: 1174547.6s
################################################################################
                     [1m Learning iteration 8/1000000 
                       Computation: 71 steps/s (collection: 1.017s, learning 0.098s)
               Value function loss: 0.0006
                    Surrogate loss: 156.1946
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.96
     action noise std distribution: [0.8220152854919434, 1.019123911857605, 1.0266536474227905, 0.8257822394371033, 1.0199968814849854, 1.0254324674606323, 0.8223448395729065, 1.022088646888733, 1.0201163291931152, 0.8213087916374207, 1.0240823030471802, 1.0266612768173218]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 720
                    Iteration time: 1.12s
                        Total time: 10.51s
                               ETA: 1167979.9s
################################################################################
                     [1m Learning iteration 9/1000000 
                       Computation: 70 steps/s (collection: 1.041s, learning 0.099s)
               Value function loss: 0.0004
                    Surrogate loss: 883.7431
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.96
     action noise std distribution: [0.8250370025634766, 1.0211412906646729, 1.0304571390151978, 0.8270317912101746, 1.0217163562774658, 1.0296382904052734, 0.8236786127090454, 1.0252103805541992, 1.0237586498260498, 0.8247195482254028, 1.0270658731460571, 1.0294588804244995]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 800
                    Iteration time: 1.14s
                        Total time: 11.65s
                               ETA: 1165208.4s
################################################################################
                    [1m Learning iteration 10/1000000 
                       Computation: 74 steps/s (collection: 0.969s, learning 0.100s)
               Value function loss: 0.0005
                    Surrogate loss: 62.3041
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.96
     action noise std distribution: [0.8278228640556335, 1.0202109813690186, 1.0350096225738525, 0.827976644039154, 1.0241169929504395, 1.0333088636398315, 0.8255046010017395, 1.0284056663513184, 1.0275990962982178, 0.8285163640975952, 1.0304806232452393, 1.0321500301361084]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 880
                    Iteration time: 1.07s
                        Total time: 12.72s
                               ETA: 1156438.1s
################################################################################
                    [1m Learning iteration 11/1000000 
                       Computation: 66 steps/s (collection: 1.097s, learning 0.100s)
               Value function loss: 0.0010
                    Surrogate loss: 243.1643
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.96
     action noise std distribution: [0.8313964605331421, 1.0209448337554932, 1.0382016897201538, 0.8305327296257019, 1.0272756814956665, 1.0363036394119263, 0.8289638161659241, 1.0308506488800049, 1.0292515754699707, 0.8322821259498596, 1.0339109897613525, 1.0348730087280273]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 960
                    Iteration time: 1.20s
                        Total time: 13.92s
                               ETA: 1159857.9s
################################################################################
                    [1m Learning iteration 12/1000000 
                       Computation: 65 steps/s (collection: 1.115s, learning 0.100s)
               Value function loss: 0.0006
                    Surrogate loss: 669.0830
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.97
     action noise std distribution: [0.8341949582099915, 1.0228642225265503, 1.0411443710327148, 0.8341183066368103, 1.0307745933532715, 1.0385850667953491, 0.8334640264511108, 1.0343328714370728, 1.0315855741500854, 0.8361859917640686, 1.0370043516159058, 1.0382742881774902]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1040
                    Iteration time: 1.21s
                        Total time: 15.13s
                               ETA: 1164095.7s
################################################################################
                    [1m Learning iteration 13/1000000 
                       Computation: 71 steps/s (collection: 1.023s, learning 0.100s)
               Value function loss: 0.0003
                    Surrogate loss: 92.6659
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.97
     action noise std distribution: [0.8373212218284607, 1.025160551071167, 1.044962763786316, 0.835173487663269, 1.0332491397857666, 1.0417355298995972, 0.8371042013168335, 1.0379053354263306, 1.0338194370269775, 0.8393288850784302, 1.0395216941833496, 1.0412976741790771]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1120
                    Iteration time: 1.12s
                        Total time: 16.26s
                               ETA: 1161180.2s
################################################################################
                    [1m Learning iteration 14/1000000 
                       Computation: 68 steps/s (collection: 1.071s, learning 0.104s)
               Value function loss: 0.0002
                    Surrogate loss: 52.1599
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.97
     action noise std distribution: [0.8391520977020264, 1.025442361831665, 1.047372817993164, 0.8360040783882141, 1.03666090965271, 1.0458545684814453, 0.8396375179290771, 1.0415904521942139, 1.0358457565307617, 0.8415157198905945, 1.0422643423080444, 1.0429396629333496]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1200
                    Iteration time: 1.17s
                        Total time: 17.43s
                               ETA: 1162066.1s
################################################################################
                    [1m Learning iteration 15/1000000 
                       Computation: 72 steps/s (collection: 1.007s, learning 0.099s)
               Value function loss: 0.0002
                    Surrogate loss: 123.6310
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.98
     action noise std distribution: [0.8406486511230469, 1.0269601345062256, 1.0488269329071045, 0.8375190496444702, 1.039448618888855, 1.0492057800292969, 0.8429489731788635, 1.045843243598938, 1.0391916036605835, 0.8442425727844238, 1.0453218221664429, 1.0451756715774536]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1280
                    Iteration time: 1.11s
                        Total time: 18.54s
                               ETA: 1158550.7s
################################################################################
                    [1m Learning iteration 16/1000000 
                       Computation: 69 steps/s (collection: 1.046s, learning 0.100s)
               Value function loss: 0.0002
                    Surrogate loss: 13.6984
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.98
     action noise std distribution: [0.842686116695404, 1.0294814109802246, 1.0501207113265991, 0.8401373624801636, 1.0412960052490234, 1.0529001951217651, 0.8460589647293091, 1.0486509799957275, 1.0424420833587646, 0.8474592566490173, 1.0463602542877197, 1.0474501848220825]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1360
                    Iteration time: 1.15s
                        Total time: 19.68s
                               ETA: 1157794.7s
################################################################################
                    [1m Learning iteration 17/1000000 
                       Computation: 72 steps/s (collection: 1.007s, learning 0.100s)
               Value function loss: 0.0002
                    Surrogate loss: 92.9877
   History latent supervision loss: 0.6963
         Leg mean action noise std: 0.98
     action noise std distribution: [0.8437895178794861, 1.0321100950241089, 1.0521812438964844, 0.8444344997406006, 1.042246699333191, 1.054079294204712, 0.8485445380210876, 1.051191806793213, 1.0459856986999512, 0.8490382432937622, 1.0462820529937744, 1.0468331575393677]
       Mean episode rew_lin_vel_xy: 0.0000
        Mean episode rew_lin_vel_z: 0.0000
        Mean episode rew_ang_vel_z: 0.0000
       Mean episode rew_ang_vel_xy: 0.0000
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: 0.0000
        Mean episode rew_joint_acc: 0.0000
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: 0.0000
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1440
                    Iteration time: 1.11s
                        Total time: 20.79s
                               ETA: 1154971.4s
################################################################################
                    [1m Learning iteration 18/1000000 
                       Computation: 70 steps/s (collection: 1.030s, learning 0.099s)
               Value function loss: 0.0209
                    Surrogate loss: 24.2437
   History latent supervision loss: 0.6963
  Privileged info regularizer loss: 0.6592
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.98
     action noise std distribution: [0.8444474935531616, 1.0327157974243164, 1.051056981086731, 0.8468971848487854, 1.0432398319244385, 1.0552634000778198, 0.8495302796363831, 1.0530352592468262, 1.0491138696670532, 0.8492758274078369, 1.0471162796020508, 1.0458089113235474]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.1032
        Mean episode rew_lin_vel_z: -0.0159
        Mean episode rew_ang_vel_z: 0.0424
       Mean episode rew_ang_vel_xy: -0.0019
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0039
        Mean episode rew_joint_acc: -0.0003
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0734
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1520
                    Iteration time: 1.13s
                        Total time: 21.92s
                               ETA: 1153571.9s
################################################################################
                    [1m Learning iteration 19/1000000 
                       Computation: 74 steps/s (collection: 0.969s, learning 0.103s)
               Value function loss: 0.0037
                    Surrogate loss: 68.1434
   History latent supervision loss: 0.6963
  Privileged info regularizer loss: 0.6035
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.98
     action noise std distribution: [0.846226692199707, 1.034122347831726, 1.0522289276123047, 0.8485844135284424, 1.0452165603637695, 1.0585681200027466, 0.8503360748291016, 1.0559288263320923, 1.0519341230392456, 0.8505040407180786, 1.0501515865325928, 1.047788381576538]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1600
                    Iteration time: 1.07s
                        Total time: 22.99s
                               ETA: 1149484.1s
################################################################################
                    [1m Learning iteration 20/1000000 
                       Computation: 72 steps/s (collection: 1.045s, learning 0.058s)
               Value function loss: 0.0037
                    Surrogate loss: 68.1434
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.6035
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.98
     action noise std distribution: [0.846226692199707, 1.034122347831726, 1.0522289276123047, 0.8485844135284424, 1.0452165603637695, 1.0585681200027466, 0.8503360748291016, 1.0559288263320923, 1.0519341230392456, 0.8505040407180786, 1.0501515865325928, 1.047788381576538]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1680
                    Iteration time: 1.10s
                        Total time: 24.09s
                               ETA: 1147294.5s
################################################################################
                    [1m Learning iteration 21/1000000 
                       Computation: 72 steps/s (collection: 1.001s, learning 0.100s)
               Value function loss: 0.0028
                    Surrogate loss: 129.7535
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.4088
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.99
     action noise std distribution: [0.8490802049636841, 1.0364619493484497, 1.0552666187286377, 0.8505249619483948, 1.0484672784805298, 1.0615841150283813, 0.8518696427345276, 1.0583289861679077, 1.0560671091079712, 0.8519506454467773, 1.0529041290283203, 1.050070881843567]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1760
                    Iteration time: 1.10s
                        Total time: 25.20s
                               ETA: 1145227.9s
################################################################################
                    [1m Learning iteration 22/1000000 
                       Computation: 73 steps/s (collection: 0.991s, learning 0.098s)
               Value function loss: 0.0009
                    Surrogate loss: 15.0856
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.3998
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.99
     action noise std distribution: [0.849728524684906, 1.0374829769134521, 1.058998942375183, 0.853247880935669, 1.0522336959838867, 1.0649958848953247, 0.8534514307975769, 1.0609350204467773, 1.0591678619384766, 0.8545594215393066, 1.0566598176956177, 1.05160653591156]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1840
                    Iteration time: 1.09s
                        Total time: 26.28s
                               ETA: 1142787.8s
################################################################################
                    [1m Learning iteration 23/1000000 
                       Computation: 72 steps/s (collection: 0.996s, learning 0.108s)
               Value function loss: 0.0006
                    Surrogate loss: 25.1562
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.3970
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.99
     action noise std distribution: [0.8516532778739929, 1.0385900735855103, 1.0613704919815063, 0.8565308451652527, 1.054626226425171, 1.0652318000793457, 0.8559173941612244, 1.0643783807754517, 1.0616014003753662, 0.857080340385437, 1.0602904558181763, 1.0543278455734253]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1920
                    Iteration time: 1.10s
                        Total time: 27.39s
                               ETA: 1141193.9s
################################################################################
                    [1m Learning iteration 24/1000000 
                       Computation: 73 steps/s (collection: 0.984s, learning 0.100s)
               Value function loss: 0.0006
                    Surrogate loss: 217.7209
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.4182
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.99
     action noise std distribution: [0.8537116646766663, 1.0413806438446045, 1.0633183717727661, 0.8591954708099365, 1.056915283203125, 1.0664440393447876, 0.8581206798553467, 1.0679833889007568, 1.0649724006652832, 0.857894241809845, 1.06246817111969, 1.0570683479309082]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2000
                    Iteration time: 1.08s
                        Total time: 28.47s
                               ETA: 1138920.0s
################################################################################
                    [1m Learning iteration 25/1000000 
                       Computation: 75 steps/s (collection: 0.958s, learning 0.101s)
               Value function loss: 0.0004
                    Surrogate loss: 731.0523
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.4523
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 0.99
     action noise std distribution: [0.8559051752090454, 1.0439096689224243, 1.0656304359436035, 0.86266028881073, 1.0588386058807373, 1.06882905960083, 0.858569324016571, 1.0713633298873901, 1.0665290355682373, 0.8606222867965698, 1.063801646232605, 1.0590193271636963]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2080
                    Iteration time: 1.06s
                        Total time: 29.53s
                               ETA: 1135864.9s
################################################################################
                    [1m Learning iteration 26/1000000 
                       Computation: 144 steps/s (collection: 0.455s, learning 0.100s)
               Value function loss: 0.0003
                    Surrogate loss: 48.6645
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.5261
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.00
     action noise std distribution: [0.8592318892478943, 1.0472019910812378, 1.06861412525177, 0.8655444979667664, 1.062315583229065, 1.0715446472167969, 0.8593480587005615, 1.0727254152297974, 1.0664349794387817, 0.862991452217102, 1.063704013824463, 1.0614879131317139]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2160
                    Iteration time: 0.55s
                        Total time: 30.09s
                               ETA: 1114335.5s
################################################################################
                    [1m Learning iteration 27/1000000 
                       Computation: 144 steps/s (collection: 0.452s, learning 0.102s)
               Value function loss: 0.0002
                    Surrogate loss: 20.7750
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.5888
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.00
     action noise std distribution: [0.8634055852890015, 1.0497057437896729, 1.0719385147094727, 0.867787778377533, 1.0656442642211914, 1.0746761560440063, 0.8610724210739136, 1.0742193460464478, 1.0677456855773926, 0.8661783337593079, 1.063461422920227, 1.0640469789505005]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2240
                    Iteration time: 0.55s
                        Total time: 30.64s
                               ETA: 1094300.0s
################################################################################
                    [1m Learning iteration 28/1000000 
                       Computation: 125 steps/s (collection: 0.528s, learning 0.109s)
               Value function loss: 0.0003
                    Surrogate loss: 1771.0028
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.6414
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.00
     action noise std distribution: [0.8658641576766968, 1.0519275665283203, 1.0733319520950317, 0.8701240420341492, 1.0678755044937134, 1.0771973133087158, 0.8624229431152344, 1.0762653350830078, 1.0699758529663086, 0.8693270683288574, 1.0653914213180542, 1.06605863571167]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2320
                    Iteration time: 0.64s
                        Total time: 31.28s
                               ETA: 1078531.4s
################################################################################
                    [1m Learning iteration 29/1000000 
                       Computation: 141 steps/s (collection: 0.463s, learning 0.102s)
               Value function loss: 0.0133
                    Surrogate loss: 2759.3566
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.6932
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.00
     action noise std distribution: [0.8692280650138855, 1.0542187690734863, 1.074338674545288, 0.874126136302948, 1.0699981451034546, 1.0806605815887451, 0.8658341765403748, 1.0810158252716064, 1.072180151939392, 0.8735781908035278, 1.0693297386169434, 1.0679638385772705]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2400
                    Iteration time: 0.57s
                        Total time: 31.84s
                               ETA: 1061420.3s
################################################################################
                    [1m Learning iteration 30/1000000 
                       Computation: 141 steps/s (collection: 0.461s, learning 0.104s)
               Value function loss: 0.0001
                    Surrogate loss: 10.9109
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.7305
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.01
     action noise std distribution: [0.8730165362358093, 1.0549715757369995, 1.075927972793579, 0.8747604489326477, 1.070370078086853, 1.0837624073028564, 0.8671914935112, 1.0844885110855103, 1.0736393928527832, 0.8772911429405212, 1.0727484226226807, 1.0708667039871216]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2480
                    Iteration time: 0.57s
                        Total time: 32.41s
                               ETA: 1045423.8s
################################################################################
                    [1m Learning iteration 31/1000000 
                       Computation: 136 steps/s (collection: 0.487s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 56.7068
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.7931
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.01
     action noise std distribution: [0.8762370944023132, 1.0571508407592773, 1.0775973796844482, 0.8762125372886658, 1.071082353591919, 1.085986852645874, 0.8693879842758179, 1.0858441591262817, 1.0755901336669922, 0.8807724714279175, 1.0758050680160522, 1.070838451385498]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2560
                    Iteration time: 0.59s
                        Total time: 33.00s
                               ETA: 1031105.0s
################################################################################
                    [1m Learning iteration 32/1000000 
                       Computation: 137 steps/s (collection: 0.479s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 233.6655
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.8496
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.01
     action noise std distribution: [0.8784576058387756, 1.0594959259033203, 1.0791330337524414, 0.8784016370773315, 1.072219729423523, 1.0881288051605225, 0.8722721338272095, 1.0878428220748901, 1.0784176588058472, 0.8828219175338745, 1.0786086320877075, 1.07200288772583]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2640
                    Iteration time: 0.58s
                        Total time: 33.58s
                               ETA: 1017447.9s
################################################################################
                    [1m Learning iteration 33/1000000 
                       Computation: 142 steps/s (collection: 0.459s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 751.1498
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.9138
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.01
     action noise std distribution: [0.8798574209213257, 1.0602113008499146, 1.0819740295410156, 0.8807452917098999, 1.071465253829956, 1.0904772281646729, 0.8745773434638977, 1.091360330581665, 1.0815129280090332, 0.8855767250061035, 1.0809581279754639, 1.0736552476882935]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2720
                    Iteration time: 0.56s
                        Total time: 34.14s
                               ETA: 1003987.6s
################################################################################
                    [1m Learning iteration 34/1000000 
                       Computation: 140 steps/s (collection: 0.470s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 78.2617
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 0.9991
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.02
     action noise std distribution: [0.8831894397735596, 1.0616599321365356, 1.0863971710205078, 0.8826902508735657, 1.0732932090759277, 1.0934300422668457, 0.8766241073608398, 1.0945188999176025, 1.0842993259429932, 0.8892285227775574, 1.0849772691726685, 1.0765364170074463]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2800
                    Iteration time: 0.57s
                        Total time: 34.71s
                               ETA: 991598.4s
################################################################################
                    [1m Learning iteration 35/1000000 
                       Computation: 128 steps/s (collection: 0.506s, learning 0.116s)
               Value function loss: 0.0000
                    Surrogate loss: 42.3274
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 1.0970
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.02
     action noise std distribution: [0.8844659924507141, 1.0645241737365723, 1.0895228385925293, 0.8838484883308411, 1.0761268138885498, 1.0956835746765137, 0.8781716227531433, 1.0969024896621704, 1.0868202447891235, 0.8919164538383484, 1.0885156393051147, 1.0799347162246704]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2880
                    Iteration time: 0.62s
                        Total time: 35.33s
                               ETA: 981318.9s
################################################################################
                    [1m Learning iteration 36/1000000 
                       Computation: 142 steps/s (collection: 0.459s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 2498.9296
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 1.1749
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.02
     action noise std distribution: [0.8855915069580078, 1.0681480169296265, 1.0928723812103271, 0.8854935169219971, 1.0792524814605713, 1.0989971160888672, 0.8799937963485718, 1.098271369934082, 1.0906400680541992, 0.8949320316314697, 1.0924798250198364, 1.0831514596939087]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2960
                    Iteration time: 0.56s
                        Total time: 35.89s
                               ETA: 969978.9s
################################################################################
                    [1m Learning iteration 37/1000000 
                       Computation: 140 steps/s (collection: 0.469s, learning 0.099s)
               Value function loss: 0.0000
                    Surrogate loss: 11.2200
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 1.2299
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.02
     action noise std distribution: [0.8886970281600952, 1.072746753692627, 1.0952796936035156, 0.888632595539093, 1.0833632946014404, 1.103377342224121, 0.8805208802223206, 1.1021369695663452, 1.095484733581543, 0.8983992338180542, 1.0957684516906738, 1.0863349437713623]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3040
                    Iteration time: 0.57s
                        Total time: 36.46s
                               ETA: 959409.5s
################################################################################
                    [1m Learning iteration 38/1000000 
                       Computation: 135 steps/s (collection: 0.487s, learning 0.105s)
               Value function loss: 0.0000
                    Surrogate loss: 2680.3840
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 1.2447
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.03
     action noise std distribution: [0.8929533362388611, 1.0776512622833252, 1.0997952222824097, 0.8930038809776306, 1.0873007774353027, 1.1079964637756348, 0.8832452893257141, 1.1070550680160522, 1.099704384803772, 0.901589572429657, 1.0979609489440918, 1.089532732963562]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3120
                    Iteration time: 0.59s
                        Total time: 37.05s
                               ETA: 949981.6s
################################################################################
                    [1m Learning iteration 39/1000000 
                       Computation: 130 steps/s (collection: 0.511s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 8.6302
   History latent supervision loss: 0.4979
  Privileged info regularizer loss: 1.2719
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.03
     action noise std distribution: [0.8936703205108643, 1.083152413368225, 1.1057082414627075, 0.9003100991249084, 1.0916972160339355, 1.1128323078155518, 0.8841631412506104, 1.1086097955703735, 1.1058272123336792, 0.9050157070159912, 1.1051324605941772, 1.090697169303894]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3200
                    Iteration time: 0.61s
                        Total time: 37.66s
                               ETA: 941521.7s
################################################################################
                    [1m Learning iteration 40/1000000 
                       Computation: 136 steps/s (collection: 0.527s, learning 0.058s)
               Value function loss: 0.0000
                    Surrogate loss: 8.6302
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 1.2719
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.03
     action noise std distribution: [0.8936703205108643, 1.083152413368225, 1.1057082414627075, 0.9003100991249084, 1.0916972160339355, 1.1128323078155518, 0.8841631412506104, 1.1086097955703735, 1.1058272123336792, 0.9050157070159912, 1.1051324605941772, 1.090697169303894]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3280
                    Iteration time: 0.59s
                        Total time: 38.25s
                               ETA: 932833.0s
################################################################################
                    [1m Learning iteration 41/1000000 
                       Computation: 139 steps/s (collection: 0.472s, learning 0.102s)
               Value function loss: 0.0002
                    Surrogate loss: 95.0703
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9925
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.04
     action noise std distribution: [0.8964523077011108, 1.0888971090316772, 1.1103522777557373, 0.907519519329071, 1.0924241542816162, 1.1164686679840088, 0.8874492645263672, 1.1114784479141235, 1.1121776103973389, 0.910548746585846, 1.1129685640335083, 1.0928466320037842]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3360
                    Iteration time: 0.57s
                        Total time: 38.82s
                               ETA: 924297.0s
################################################################################
                    [1m Learning iteration 42/1000000 
                       Computation: 126 steps/s (collection: 0.535s, learning 0.099s)
               Value function loss: 0.0050
                    Surrogate loss: 1369.2072
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9760
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.04
     action noise std distribution: [0.9005241394042969, 1.0920864343643188, 1.1135507822036743, 0.9113581776618958, 1.0922784805297852, 1.119276523590088, 0.8910568356513977, 1.1126842498779297, 1.115517020225525, 0.9123231172561646, 1.1168010234832764, 1.095622181892395]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3440
                    Iteration time: 0.63s
                        Total time: 39.46s
                               ETA: 917552.0s
################################################################################
                    [1m Learning iteration 43/1000000 
                       Computation: 134 steps/s (collection: 0.490s, learning 0.103s)
               Value function loss: 0.0026
                    Surrogate loss: 9.9994
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9677
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.04
     action noise std distribution: [0.9049188494682312, 1.0953150987625122, 1.1138478517532349, 0.9134656190872192, 1.0953196287155151, 1.1187524795532227, 0.893127977848053, 1.1154862642288208, 1.1191577911376953, 0.912912905216217, 1.1206021308898926, 1.0959099531173706]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3520
                    Iteration time: 0.59s
                        Total time: 40.05s
                               ETA: 910179.6s
################################################################################
                    [1m Learning iteration 44/1000000 
                       Computation: 134 steps/s (collection: 0.496s, learning 0.099s)
               Value function loss: 0.0001
                    Surrogate loss: 56.2978
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9734
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.05
     action noise std distribution: [0.9087762832641602, 1.0986623764038086, 1.1167716979980469, 0.9177340865135193, 1.1012071371078491, 1.1219457387924194, 0.8967053294181824, 1.116886854171753, 1.1240566968917847, 0.9157029390335083, 1.1255420446395874, 1.0985158681869507]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3600
                    Iteration time: 0.60s
                        Total time: 40.65s
                               ETA: 903182.8s
################################################################################
                    [1m Learning iteration 45/1000000 
                       Computation: 127 steps/s (collection: 0.515s, learning 0.112s)
               Value function loss: 0.0000
                    Surrogate loss: 204.3869
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9155
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.05
     action noise std distribution: [0.9122499227523804, 1.1023725271224976, 1.120719075202942, 0.9209704995155334, 1.103649616241455, 1.1232751607894897, 0.897180438041687, 1.1192976236343384, 1.1264009475708008, 0.9171981811523438, 1.1266015768051147, 1.1015485525131226]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3680
                    Iteration time: 0.63s
                        Total time: 41.27s
                               ETA: 897178.1s
################################################################################
                    [1m Learning iteration 46/1000000 
                       Computation: 103 steps/s (collection: 0.675s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 30.3332
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9118
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.05
     action noise std distribution: [0.9167001843452454, 1.105649709701538, 1.1259673833847046, 0.9199573397636414, 1.1063194274902344, 1.1257332563400269, 0.9008023738861084, 1.121508240699768, 1.1321916580200195, 0.9210480451583862, 1.1304750442504883, 1.1074367761611938]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3760
                    Iteration time: 0.78s
                        Total time: 42.05s
                               ETA: 894609.0s
################################################################################
                    [1m Learning iteration 47/1000000 
                       Computation: 134 steps/s (collection: 0.494s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 26.1488
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8857
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.06
     action noise std distribution: [0.9221250414848328, 1.110558032989502, 1.1311872005462646, 0.9205151796340942, 1.112048864364624, 1.1306185722351074, 0.9076266884803772, 1.124742865562439, 1.1383157968521118, 0.9258396029472351, 1.1362825632095337, 1.113399863243103]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3840
                    Iteration time: 0.60s
                        Total time: 42.64s
                               ETA: 888373.1s
################################################################################
                    [1m Learning iteration 48/1000000 
                       Computation: 129 steps/s (collection: 0.505s, learning 0.112s)
               Value function loss: 0.0000
                    Surrogate loss: 22.2848
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8524
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.06
     action noise std distribution: [0.9256803393363953, 1.1154472827911377, 1.1340702772140503, 0.9218417406082153, 1.1168196201324463, 1.1342391967773438, 0.9094617962837219, 1.126505732536316, 1.142646312713623, 0.9285265207290649, 1.1409657001495361, 1.1154206991195679]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3920
                    Iteration time: 0.62s
                        Total time: 43.26s
                               ETA: 882828.0s
################################################################################
                    [1m Learning iteration 49/1000000 
                       Computation: 136 steps/s (collection: 0.482s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 20.0028
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8172
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.06
     action noise std distribution: [0.9267481565475464, 1.116606593132019, 1.137595772743225, 0.9249778985977173, 1.1203230619430542, 1.1376478672027588, 0.9115182161331177, 1.129032850265503, 1.1453471183776855, 0.9290794134140015, 1.143694281578064, 1.1189268827438354]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4000
                    Iteration time: 0.58s
                        Total time: 43.85s
                               ETA: 876858.2s
################################################################################
                    [1m Learning iteration 50/1000000 
                       Computation: 133 steps/s (collection: 0.497s, learning 0.104s)
               Value function loss: 0.0000
                    Surrogate loss: 28.5483
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8408
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.07
     action noise std distribution: [0.9302520155906677, 1.1213347911834717, 1.1358122825622559, 0.928136944770813, 1.124764084815979, 1.1417120695114136, 0.9161253571510315, 1.1322005987167358, 1.1488627195358276, 0.9327746629714966, 1.1479637622833252, 1.123772382736206]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4080
                    Iteration time: 0.60s
                        Total time: 44.45s
                               ETA: 871447.6s
################################################################################
                    [1m Learning iteration 51/1000000 
                       Computation: 134 steps/s (collection: 0.489s, learning 0.107s)
               Value function loss: 0.0000
                    Surrogate loss: 12.3738
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8434
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.07
     action noise std distribution: [0.9330299496650696, 1.122855305671692, 1.1357011795043945, 0.930023193359375, 1.1270562410354614, 1.1441043615341187, 0.9177489876747131, 1.132114052772522, 1.151314377784729, 0.9356629848480225, 1.1499686241149902, 1.1262975931167603]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4160
                    Iteration time: 0.60s
                        Total time: 45.04s
                               ETA: 866159.7s
################################################################################
                    [1m Learning iteration 52/1000000 
                       Computation: 131 steps/s (collection: 0.512s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 979.7767
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.8545
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.07
     action noise std distribution: [0.936161994934082, 1.1213629245758057, 1.1388487815856934, 0.9320939183235168, 1.1292684078216553, 1.1475516557693481, 0.9179732799530029, 1.1314321756362915, 1.1535706520080566, 0.9375861883163452, 1.1512537002563477, 1.128338098526001]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4240
                    Iteration time: 0.61s
                        Total time: 45.65s
                               ETA: 861321.7s
################################################################################
                    [1m Learning iteration 53/1000000 
                       Computation: 136 steps/s (collection: 0.487s, learning 0.099s)
               Value function loss: 0.0000
                    Surrogate loss: 35.8769
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9245
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.07
     action noise std distribution: [0.942340075969696, 1.1249088048934937, 1.1443350315093994, 0.9342302680015564, 1.1344319581985474, 1.1528278589248657, 0.9214918613433838, 1.1300727128982544, 1.1567047834396362, 0.9434808492660522, 1.1538097858428955, 1.1300898790359497]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4320
                    Iteration time: 0.59s
                        Total time: 46.24s
                               ETA: 856229.2s
################################################################################
                    [1m Learning iteration 54/1000000 
                       Computation: 133 steps/s (collection: 0.497s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 18.0049
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9625
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.08
     action noise std distribution: [0.9438570141792297, 1.1276062726974487, 1.1477147340774536, 0.9385127425193787, 1.1382218599319458, 1.158889651298523, 0.9265218377113342, 1.134155035018921, 1.1597532033920288, 0.9510058164596558, 1.1551334857940674, 1.1318000555038452]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4400
                    Iteration time: 0.60s
                        Total time: 46.84s
                               ETA: 851526.9s
################################################################################
                    [1m Learning iteration 55/1000000 
                       Computation: 129 steps/s (collection: 0.518s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 277.7123
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9708
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.08
     action noise std distribution: [0.9438999891281128, 1.1302520036697388, 1.15385103225708, 0.9411590099334717, 1.1410804986953735, 1.1642091274261475, 0.9298012256622314, 1.137149691581726, 1.1653939485549927, 0.9568718075752258, 1.161775827407837, 1.1299530267715454]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4480
                    Iteration time: 0.62s
                        Total time: 47.46s
                               ETA: 847375.4s
################################################################################
                    [1m Learning iteration 56/1000000 
                       Computation: 135 steps/s (collection: 0.486s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 42.6675
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9690
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.08
     action noise std distribution: [0.9443994164466858, 1.1341536045074463, 1.161568284034729, 0.9439446926116943, 1.1451599597930908, 1.1681151390075684, 0.9329389333724976, 1.1419411897659302, 1.1717404127120972, 0.9627651572227478, 1.170613408088684, 1.1317880153656006]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4560
                    Iteration time: 0.59s
                        Total time: 48.04s
                               ETA: 842832.1s
################################################################################
                    [1m Learning iteration 57/1000000 
                       Computation: 135 steps/s (collection: 0.487s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 27.9669
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9867
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.09
     action noise std distribution: [0.9488782286643982, 1.1385489702224731, 1.1652532815933228, 0.9459249377250671, 1.1472183465957642, 1.1695796251296997, 0.9393959641456604, 1.1465442180633545, 1.1783033609390259, 0.9694420099258423, 1.177293300628662, 1.1330403089523315]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4640
                    Iteration time: 0.59s
                        Total time: 48.63s
                               ETA: 838454.3s
################################################################################
                    [1m Learning iteration 58/1000000 
                       Computation: 133 steps/s (collection: 0.485s, learning 0.113s)
               Value function loss: 0.0000
                    Surrogate loss: 158.7309
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 0.9990
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.09
     action noise std distribution: [0.952501118183136, 1.1428362131118774, 1.1699217557907104, 0.9467374086380005, 1.147059679031372, 1.1734638214111328, 0.9458361864089966, 1.1525304317474365, 1.1817079782485962, 0.9751260876655579, 1.1818443536758423, 1.1366817951202393]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4720
                    Iteration time: 0.60s
                        Total time: 49.23s
                               ETA: 834379.4s
################################################################################
                    [1m Learning iteration 59/1000000 
                       Computation: 133 steps/s (collection: 0.500s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 26.7544
   History latent supervision loss: 1.1543
  Privileged info regularizer loss: 1.0056
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.10
     action noise std distribution: [0.9498202800750732, 1.1478620767593384, 1.1734117269515991, 0.9490176439285278, 1.1481670141220093, 1.1792172193527222, 0.949748694896698, 1.1589946746826172, 1.1833665370941162, 0.97952800989151, 1.1873986721038818, 1.1426185369491577]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4800
                    Iteration time: 0.60s
                        Total time: 49.83s
                               ETA: 830480.7s
################################################################################
                    [1m Learning iteration 60/1000000 
                       Computation: 143 steps/s (collection: 0.499s, learning 0.059s)
               Value function loss: 0.0000
                    Surrogate loss: 26.7544
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.0056
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.10
     action noise std distribution: [0.9498202800750732, 1.1478620767593384, 1.1734117269515991, 0.9490176439285278, 1.1481670141220093, 1.1792172193527222, 0.949748694896698, 1.1589946746826172, 1.1833665370941162, 0.97952800989151, 1.1873986721038818, 1.1426185369491577]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4880
                    Iteration time: 0.56s
                        Total time: 50.39s
                               ETA: 826018.0s
################################################################################
                    [1m Learning iteration 61/1000000 
                       Computation: 134 steps/s (collection: 0.490s, learning 0.104s)
               Value function loss: 0.0000
                    Surrogate loss: 107.8493
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7324
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.10
     action noise std distribution: [0.9493959546089172, 1.1543489694595337, 1.1778427362442017, 0.9515604376792908, 1.149090051651001, 1.184113621711731, 0.9540950655937195, 1.1653921604156494, 1.185856580734253, 0.9807056188583374, 1.1920009851455688, 1.1474437713623047]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4960
                    Iteration time: 0.59s
                        Total time: 50.98s
                               ETA: 822271.4s
################################################################################
                    [1m Learning iteration 62/1000000 
                       Computation: 130 steps/s (collection: 0.512s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 67.4309
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7473
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.10
     action noise std distribution: [0.9526745080947876, 1.1585420370101929, 1.1802682876586914, 0.9526082277297974, 1.1518206596374512, 1.1877754926681519, 0.9592764377593994, 1.1726939678192139, 1.189205527305603, 0.9833810925483704, 1.1967397928237915, 1.15193510055542]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5040
                    Iteration time: 0.61s
                        Total time: 51.60s
                               ETA: 818964.0s
################################################################################
                    [1m Learning iteration 63/1000000 
                       Computation: 136 steps/s (collection: 0.486s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 30.8049
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7515
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.11
     action noise std distribution: [0.9560801982879639, 1.1627751588821411, 1.1835156679153442, 0.9571965932846069, 1.1552386283874512, 1.1920121908187866, 0.962576687335968, 1.1793521642684937, 1.1916489601135254, 0.9858183860778809, 1.2001690864562988, 1.1575124263763428]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5120
                    Iteration time: 0.59s
                        Total time: 52.18s
                               ETA: 815336.8s
################################################################################
                    [1m Learning iteration 64/1000000 
                       Computation: 134 steps/s (collection: 0.497s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 168379.2645
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7478
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.11
     action noise std distribution: [0.9600545167922974, 1.1675785779953003, 1.1856800317764282, 0.9633497595787048, 1.1595724821090698, 1.195006251335144, 0.9621015787124634, 1.1826705932617188, 1.1950591802597046, 0.9899834990501404, 1.2039785385131836, 1.1629446744918823]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5200
                    Iteration time: 0.60s
                        Total time: 52.78s
                               ETA: 811972.1s
################################################################################
                    [1m Learning iteration 65/1000000 
                       Computation: 130 steps/s (collection: 0.512s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 211.9428
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7493
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.11
     action noise std distribution: [0.9633108377456665, 1.1738412380218506, 1.1898777484893799, 0.9669662714004517, 1.1636178493499756, 1.1991183757781982, 0.9645872712135315, 1.1860071420669556, 1.1998158693313599, 0.9952624440193176, 1.2074558734893799, 1.1683019399642944]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5280
                    Iteration time: 0.61s
                        Total time: 53.39s
                               ETA: 808952.9s
################################################################################
                    [1m Learning iteration 66/1000000 
                       Computation: 134 steps/s (collection: 0.493s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 310.1068
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7650
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.12
     action noise std distribution: [0.9652981758117676, 1.1785099506378174, 1.1962357759475708, 0.9707481265068054, 1.1671136617660522, 1.2035421133041382, 0.9687942266464233, 1.1900076866149902, 1.2027254104614258, 1.0000962018966675, 1.2082716226577759, 1.1724106073379517]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5360
                    Iteration time: 0.59s
                        Total time: 53.99s
                               ETA: 805727.4s
################################################################################
                    [1m Learning iteration 67/1000000 
                       Computation: 135 steps/s (collection: 0.491s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 44.6636
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7731
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.12
     action noise std distribution: [0.9696977138519287, 1.1814525127410889, 1.2010176181793213, 0.9732648730278015, 1.1719870567321777, 1.2091416120529175, 0.9738274812698364, 1.1918442249298096, 1.2053147554397583, 1.0033246278762817, 1.2101356983184814, 1.1767932176589966]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5440
                    Iteration time: 0.59s
                        Total time: 54.58s
                               ETA: 802571.5s
################################################################################
                    [1m Learning iteration 68/1000000 
                       Computation: 132 steps/s (collection: 0.485s, learning 0.117s)
               Value function loss: 0.0000
                    Surrogate loss: 191.6361
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.7715
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.13
     action noise std distribution: [0.973982036113739, 1.1850866079330444, 1.2057597637176514, 0.9765645265579224, 1.176712155342102, 1.2130557298660278, 0.979241132736206, 1.194856882095337, 1.209588646888733, 1.0087941884994507, 1.2134231328964233, 1.1792182922363281]
                       Mean reward: 3.12
               Mean episode length: 748.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3176
        Mean episode rew_lin_vel_z: -0.0488
        Mean episode rew_ang_vel_z: 0.1303
       Mean episode rew_ang_vel_xy: -0.0057
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0120
        Mean episode rew_joint_acc: -0.0011
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2258
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5520
                    Iteration time: 0.60s
                        Total time: 55.18s
                               ETA: 799669.7s
################################################################################
                    [1m Learning iteration 69/1000000 
                       Computation: 116 steps/s (collection: 0.589s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 7749.8580
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 0.8227
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.13
     action noise std distribution: [0.9765878915786743, 1.1849253177642822, 1.2100255489349365, 0.9814744591712952, 1.1796483993530273, 1.2159942388534546, 0.9827427864074707, 1.1999036073684692, 1.214740514755249, 1.014113187789917, 1.2165427207946777, 1.1815860271453857]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.2636
        Mean episode rew_lin_vel_z: -0.0471
        Mean episode rew_ang_vel_z: 0.1085
       Mean episode rew_ang_vel_xy: -0.0064
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0107
        Mean episode rew_joint_acc: -0.0010
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2024
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5600
                    Iteration time: 0.69s
                        Total time: 55.87s
                               ETA: 798045.0s
################################################################################
                    [1m Learning iteration 70/1000000 
                       Computation: 72 steps/s (collection: 1.005s, learning 0.103s)
               Value function loss: 0.0002
                    Surrogate loss: 2858.5311
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.0213
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.13
     action noise std distribution: [0.9789372682571411, 1.1865938901901245, 1.21244478225708, 0.9852731227874756, 1.1823745965957642, 1.2186651229858398, 0.9850824475288391, 1.2020373344421387, 1.21854829788208, 1.0186697244644165, 1.2189483642578125, 1.1844078302383423]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5680
                    Iteration time: 1.11s
                        Total time: 56.97s
                               ETA: 802405.2s
################################################################################
                    [1m Learning iteration 71/1000000 
                       Computation: 71 steps/s (collection: 1.019s, learning 0.102s)
               Value function loss: 0.0001
                    Surrogate loss: 105.7589
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.2158
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.14
     action noise std distribution: [0.9818663597106934, 1.1911416053771973, 1.215998649597168, 0.9893797636032104, 1.1857157945632935, 1.2210758924484253, 0.9869554042816162, 1.2054260969161987, 1.2220021486282349, 1.0226975679397583, 1.2222790718078613, 1.1880534887313843]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5760
                    Iteration time: 1.12s
                        Total time: 58.10s
                               ETA: 806826.3s
################################################################################
                    [1m Learning iteration 72/1000000 
                       Computation: 67 steps/s (collection: 1.080s, learning 0.101s)
               Value function loss: 0.0001
                    Surrogate loss: 247.7850
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.2794
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.14
     action noise std distribution: [0.9840774536132812, 1.1962006092071533, 1.2191715240478516, 0.9945085644721985, 1.189444661140442, 1.22428560256958, 0.9890470504760742, 1.2098420858383179, 1.2270854711532593, 1.0276671648025513, 1.2260212898254395, 1.1922883987426758]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5840
                    Iteration time: 1.18s
                        Total time: 59.28s
                               ETA: 811948.2s
################################################################################
                    [1m Learning iteration 73/1000000 
                       Computation: 71 steps/s (collection: 1.020s, learning 0.100s)
               Value function loss: 0.0001
                    Surrogate loss: 233.9166
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.3326
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.14
     action noise std distribution: [0.9880925416946411, 1.200128197669983, 1.2227486371994019, 0.9979106783866882, 1.1948825120925903, 1.2273796796798706, 0.99358731508255, 1.2132524251937866, 1.232121467590332, 1.0316548347473145, 1.2313629388809204, 1.196618676185608]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5920
                    Iteration time: 1.12s
                        Total time: 60.40s
                               ETA: 816108.9s
################################################################################
                    [1m Learning iteration 74/1000000 
                       Computation: 65 steps/s (collection: 1.115s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 63.8148
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.4286
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.15
     action noise std distribution: [0.9930428266525269, 1.2039605379104614, 1.2283668518066406, 1.0011818408966064, 1.2012776136398315, 1.2289698123931885, 0.9992481470108032, 1.2150555849075317, 1.2352492809295654, 1.0341458320617676, 1.2372981309890747, 1.2017163038253784]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6000
                    Iteration time: 1.21s
                        Total time: 61.61s
                               ETA: 821389.4s
################################################################################
                    [1m Learning iteration 75/1000000 
                       Computation: 70 steps/s (collection: 1.033s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 1887.1804
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.5102
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.15
     action noise std distribution: [0.9961141347885132, 1.206097960472107, 1.2340571880340576, 1.0029577016830444, 1.2069618701934814, 1.2320122718811035, 1.0044840574264526, 1.2186206579208374, 1.2367373704910278, 1.0361957550048828, 1.2417868375778198, 1.2071884870529175]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6080
                    Iteration time: 1.13s
                        Total time: 62.74s
                               ETA: 825494.3s
################################################################################
                    [1m Learning iteration 76/1000000 
                       Computation: 60 steps/s (collection: 1.223s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 586.3513
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.4451
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [0.9968761205673218, 1.2098649740219116, 1.2377681732177734, 1.005375862121582, 1.2113670110702515, 1.2377498149871826, 1.0087685585021973, 1.223494529724121, 1.238356113433838, 1.0403051376342773, 1.2463771104812622, 1.2123920917510986]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6160
                    Iteration time: 1.32s
                        Total time: 64.06s
                               ETA: 831924.4s
################################################################################
                    [1m Learning iteration 77/1000000 
                       Computation: 58 steps/s (collection: 1.269s, learning 0.099s)
               Value function loss: 0.0000
                    Surrogate loss: 8.1597
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.3566
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [0.9993545413017273, 1.2123085260391235, 1.24173104763031, 1.0090715885162354, 1.2134991884231567, 1.2409247159957886, 1.0125503540039062, 1.2247940301895142, 1.2412447929382324, 1.0423815250396729, 1.2491015195846558, 1.2142664194107056]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6240
                    Iteration time: 1.37s
                        Total time: 65.43s
                               ETA: 838800.2s
################################################################################
                    [1m Learning iteration 78/1000000 
                       Computation: 63 steps/s (collection: 1.154s, learning 0.099s)
               Value function loss: 0.0000
                    Surrogate loss: 695.0040
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.2809
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [1.0025347471237183, 1.215179681777954, 1.2462272644042969, 1.010916829109192, 1.2148815393447876, 1.242862582206726, 1.0161967277526855, 1.2271085977554321, 1.2436050176620483, 1.0425504446029663, 1.2507832050323486, 1.2169941663742065]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6320
                    Iteration time: 1.25s
                        Total time: 66.69s
                               ETA: 844048.3s
################################################################################
                    [1m Learning iteration 79/1000000 
                       Computation: 60 steps/s (collection: 1.221s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 107.0436
   History latent supervision loss: 0.8742
  Privileged info regularizer loss: 1.1174
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [1.005474328994751, 1.2174527645111084, 1.2492225170135498, 1.011702060699463, 1.216416358947754, 1.2452237606048584, 1.019652009010315, 1.2301942110061646, 1.2462056875228882, 1.0437670946121216, 1.2520923614501953, 1.2182042598724365]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6400
                    Iteration time: 1.32s
                        Total time: 68.00s
                               ETA: 849962.6s
################################################################################
                    [1m Learning iteration 80/1000000 
                       Computation: 64 steps/s (collection: 1.174s, learning 0.063s)
               Value function loss: 0.0000
                    Surrogate loss: 107.0436
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.1174
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [1.005474328994751, 1.2174527645111084, 1.2492225170135498, 1.011702060699463, 1.216416358947754, 1.2452237606048584, 1.019652009010315, 1.2301942110061646, 1.2462056875228882, 1.0437670946121216, 1.2520923614501953, 1.2182042598724365]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6480
                    Iteration time: 1.24s
                        Total time: 69.24s
                               ETA: 854740.4s
################################################################################
                    [1m Learning iteration 81/1000000 
                       Computation: 63 steps/s (collection: 1.160s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 10.3936
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 0.5402
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [1.0073323249816895, 1.218122124671936, 1.2506861686706543, 1.0127686262130737, 1.217484474182129, 1.2470834255218506, 1.020766258239746, 1.2323803901672363, 1.2456960678100586, 1.0441153049468994, 1.2530032396316528, 1.2181551456451416]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6560
                    Iteration time: 1.26s
                        Total time: 70.50s
                               ETA: 859653.6s
################################################################################
                    [1m Learning iteration 82/1000000 
                       Computation: 62 steps/s (collection: 1.189s, learning 0.099s)
               Value function loss: 0.0001
                    Surrogate loss: 47.8592
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 0.5017
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.16
     action noise std distribution: [1.008583664894104, 1.2181380987167358, 1.25189208984375, 1.0143128633499146, 1.217514991760254, 1.2487988471984863, 1.0222790241241455, 1.2334177494049072, 1.245638370513916, 1.044637680053711, 1.2541413307189941, 1.2192085981369019]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6640
                    Iteration time: 1.29s
                        Total time: 71.79s
                               ETA: 864817.0s
################################################################################
                    [1m Learning iteration 83/1000000 
                       Computation: 63 steps/s (collection: 1.144s, learning 0.107s)
               Value function loss: 0.0000
                    Surrogate loss: 11.9668
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 0.4961
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.17
     action noise std distribution: [1.0095781087875366, 1.2176775932312012, 1.251980185508728, 1.0158051252365112, 1.2179521322250366, 1.2502583265304565, 1.0236337184906006, 1.2338422536849976, 1.2468981742858887, 1.045528531074524, 1.2550321817398071, 1.2200560569763184]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6720
                    Iteration time: 1.25s
                        Total time: 73.04s
                               ETA: 869407.2s
################################################################################
                    [1m Learning iteration 84/1000000 
                       Computation: 62 steps/s (collection: 1.177s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 161.1763
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 0.8254
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.17
     action noise std distribution: [1.0103832483291626, 1.218071460723877, 1.2520198822021484, 1.0169613361358643, 1.2186150550842285, 1.2514917850494385, 1.024569034576416, 1.2349052429199219, 1.2482105493545532, 1.0461748838424683, 1.2558043003082275, 1.220491647720337]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6800
                    Iteration time: 1.27s
                        Total time: 74.31s
                               ETA: 874168.4s
################################################################################
                    [1m Learning iteration 85/1000000 
                       Computation: 60 steps/s (collection: 1.218s, learning 0.101s)
               Value function loss: 0.0001
                    Surrogate loss: 75.4514
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.2279
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.17
     action noise std distribution: [1.0120289325714111, 1.2189562320709229, 1.2542625665664673, 1.0185800790786743, 1.2205954790115356, 1.254051923751831, 1.0271645784378052, 1.2371199131011963, 1.2488683462142944, 1.0475960969924927, 1.2569732666015625, 1.2222164869308472]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6880
                    Iteration time: 1.32s
                        Total time: 75.63s
                               ETA: 879335.2s
################################################################################
                    [1m Learning iteration 86/1000000 
                       Computation: 63 steps/s (collection: 1.155s, learning 0.099s)
               Value function loss: 0.0001
                    Surrogate loss: 101.1738
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4037
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.17
     action noise std distribution: [1.015333890914917, 1.221496343612671, 1.2583410739898682, 1.021701693534851, 1.224657416343689, 1.2575358152389526, 1.0296977758407593, 1.240320086479187, 1.248858094215393, 1.049657940864563, 1.2586251497268677, 1.2234982252120972]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6960
                    Iteration time: 1.25s
                        Total time: 76.88s
                               ETA: 883631.7s
################################################################################
                    [1m Learning iteration 87/1000000 
                       Computation: 61 steps/s (collection: 1.193s, learning 0.100s)
               Value function loss: 0.0002
                    Surrogate loss: 71.3597
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4245
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.17
     action noise std distribution: [1.0178203582763672, 1.2234432697296143, 1.2607365846633911, 1.0237915515899658, 1.2272307872772217, 1.2585941553115845, 1.0314173698425293, 1.2423902750015259, 1.249936819076538, 1.0514159202575684, 1.2608025074005127, 1.2235435247421265]
                       Mean reward: 1.56
               Mean episode length: 1397.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0090
        Mean episode rew_lin_vel_z: -0.0391
        Mean episode rew_ang_vel_z: 0.0056
       Mean episode rew_ang_vel_xy: -0.0095
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0046
        Mean episode rew_joint_acc: -0.0005
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.0923
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7040
                    Iteration time: 1.29s
                        Total time: 78.17s
                               ETA: 888273.8s
################################################################################
                    [1m Learning iteration 88/1000000 
                       Computation: 62 steps/s (collection: 1.173s, learning 0.101s)
               Value function loss: 0.0004
                    Surrogate loss: 159.0224
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4540
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.18
     action noise std distribution: [1.0197988748550415, 1.2276604175567627, 1.2640044689178467, 1.0271910429000854, 1.230555772781372, 1.2603377103805542, 1.0352948904037476, 1.2450077533721924, 1.2533406019210815, 1.052493929862976, 1.2639576196670532, 1.2237199544906616]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0219
        Mean episode rew_lin_vel_z: -0.0433
        Mean episode rew_ang_vel_z: 0.0635
       Mean episode rew_ang_vel_xy: -0.0080
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0106
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1985
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7120
                    Iteration time: 1.27s
                        Total time: 79.45s
                               ETA: 892609.1s
################################################################################
                    [1m Learning iteration 89/1000000 
                       Computation: 61 steps/s (collection: 1.191s, learning 0.100s)
               Value function loss: 0.0040
                    Surrogate loss: 42.9410
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4033
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.18
     action noise std distribution: [1.0227235555648804, 1.228948712348938, 1.2674371004104614, 1.0307105779647827, 1.2329964637756348, 1.262374997138977, 1.037880778312683, 1.2464276552200317, 1.2559415102005005, 1.0540213584899902, 1.2662936449050903, 1.224517583847046]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 1.29s
                        Total time: 80.74s
                               ETA: 897029.2s
################################################################################
                    [1m Learning iteration 90/1000000 
                       Computation: 60 steps/s (collection: 1.233s, learning 0.098s)
               Value function loss: 0.0016
                    Surrogate loss: 23.8158
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4103
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.18
     action noise std distribution: [1.0254236459732056, 1.2286853790283203, 1.2709407806396484, 1.0327991247177124, 1.2359668016433716, 1.2653688192367554, 1.0404939651489258, 1.2493351697921753, 1.2580747604370117, 1.0575870275497437, 1.2707386016845703, 1.2267309427261353]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7280
                    Iteration time: 1.33s
                        Total time: 82.07s
                               ETA: 901793.4s
################################################################################
                    [1m Learning iteration 91/1000000 
                       Computation: 67 steps/s (collection: 1.081s, learning 0.100s)
               Value function loss: 0.0047
                    Surrogate loss: 104.8626
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4223
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.18
     action noise std distribution: [1.029398798942566, 1.2328319549560547, 1.2744166851043701, 1.0342178344726562, 1.2383110523223877, 1.269208312034607, 1.0439772605895996, 1.252114176750183, 1.2605056762695312, 1.0613542795181274, 1.2756704092025757, 1.231169581413269]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7360
                    Iteration time: 1.18s
                        Total time: 83.25s
                               ETA: 904824.6s
################################################################################
                    [1m Learning iteration 92/1000000 
                       Computation: 61 steps/s (collection: 1.194s, learning 0.097s)
               Value function loss: 0.0014
                    Surrogate loss: 40.9454
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4278
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.19
     action noise std distribution: [1.0311955213546753, 1.2355703115463257, 1.276330590248108, 1.0373724699020386, 1.2414913177490234, 1.271183729171753, 1.0465974807739258, 1.25213623046875, 1.2638378143310547, 1.0643259286880493, 1.2802646160125732, 1.2343820333480835]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7440
                    Iteration time: 1.29s
                        Total time: 84.54s
                               ETA: 908976.3s
################################################################################
                    [1m Learning iteration 93/1000000 
                       Computation: 60 steps/s (collection: 1.231s, learning 0.101s)
               Value function loss: 0.0019
                    Surrogate loss: 18.1294
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.4633
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.19
     action noise std distribution: [1.0349153280258179, 1.2380192279815674, 1.2788890600204468, 1.0416492223739624, 1.2458240985870361, 1.2731406688690186, 1.049518346786499, 1.2544564008712769, 1.2664414644241333, 1.0654375553131104, 1.2829837799072266, 1.2377017736434937]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7520
                    Iteration time: 1.33s
                        Total time: 85.87s
                               ETA: 913472.7s
################################################################################
                    [1m Learning iteration 94/1000000 
                       Computation: 63 steps/s (collection: 1.148s, learning 0.105s)
               Value function loss: 0.0014
                    Surrogate loss: 16.4785
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5186
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.19
     action noise std distribution: [1.0404263734817505, 1.2392135858535767, 1.2824794054031372, 1.0453051328659058, 1.2505524158477783, 1.2780613899230957, 1.05316162109375, 1.2589154243469238, 1.269881248474121, 1.0678024291992188, 1.2857980728149414, 1.2412467002868652]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7600
                    Iteration time: 1.25s
                        Total time: 87.13s
                               ETA: 917040.7s
################################################################################
                    [1m Learning iteration 95/1000000 
                       Computation: 63 steps/s (collection: 1.150s, learning 0.100s)
               Value function loss: 0.0011
                    Surrogate loss: 46.7089
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5232
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.20
     action noise std distribution: [1.0444461107254028, 1.2424026727676392, 1.2864062786102295, 1.049415946006775, 1.2524124383926392, 1.282563328742981, 1.0576703548431396, 1.2604135274887085, 1.2720891237258911, 1.0693000555038452, 1.2898231744766235, 1.24430251121521]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7680
                    Iteration time: 1.25s
                        Total time: 88.38s
                               ETA: 920508.8s
################################################################################
                    [1m Learning iteration 96/1000000 
                       Computation: 60 steps/s (collection: 1.226s, learning 0.099s)
               Value function loss: 0.0009
                    Surrogate loss: 134.3954
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5526
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.20
     action noise std distribution: [1.0458277463912964, 1.2464203834533691, 1.2912161350250244, 1.0541603565216064, 1.2536647319793701, 1.2863372564315796, 1.063506007194519, 1.2621654272079468, 1.276463270187378, 1.071579933166504, 1.2948471307754517, 1.2486048936843872]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7760
                    Iteration time: 1.33s
                        Total time: 89.70s
                               ETA: 924678.9s
################################################################################
                    [1m Learning iteration 97/1000000 
                       Computation: 64 steps/s (collection: 1.134s, learning 0.100s)
               Value function loss: 0.0007
                    Surrogate loss: 227.2415
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5624
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.20
     action noise std distribution: [1.0495269298553467, 1.2498815059661865, 1.2941868305206299, 1.057851791381836, 1.2566030025482178, 1.2889206409454346, 1.0674312114715576, 1.2643496990203857, 1.2814958095550537, 1.0736973285675049, 1.2989647388458252, 1.2517858743667603]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7840
                    Iteration time: 1.23s
                        Total time: 90.94s
                               ETA: 927832.6s
################################################################################
                    [1m Learning iteration 98/1000000 
                       Computation: 62 steps/s (collection: 1.174s, learning 0.100s)
               Value function loss: 0.0007
                    Surrogate loss: 215.8804
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5738
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.21
     action noise std distribution: [1.0524708032608032, 1.2511043548583984, 1.2968660593032837, 1.0612233877182007, 1.2601656913757324, 1.2924079895019531, 1.0710519552230835, 1.2677887678146362, 1.2860265970230103, 1.0743615627288818, 1.3034842014312744, 1.2556884288787842]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7920
                    Iteration time: 1.27s
                        Total time: 92.21s
                               ETA: 931333.2s
################################################################################
                    [1m Learning iteration 99/1000000 
                       Computation: 61 steps/s (collection: 1.207s, learning 0.102s)
               Value function loss: 0.0007
                    Surrogate loss: 156.3932
   History latent supervision loss: 0.7551
  Privileged info regularizer loss: 1.5028
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.21
     action noise std distribution: [1.0562711954116821, 1.252637505531311, 1.3004344701766968, 1.063446044921875, 1.2634674310684204, 1.2964277267456055, 1.074308156967163, 1.2718411684036255, 1.288989543914795, 1.0767475366592407, 1.3088401556015015, 1.258864164352417]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8000
                    Iteration time: 1.31s
                        Total time: 93.52s
                               ETA: 935108.9s
################################################################################
                    [1m Learning iteration 100/1000000 
                       Computation: 66 steps/s (collection: 1.150s, learning 0.060s)
               Value function loss: 0.0007
                    Surrogate loss: 156.3932
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 1.5028
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.21
     action noise std distribution: [1.0562711954116821, 1.252637505531311, 1.3004344701766968, 1.063446044921875, 1.2634674310684204, 1.2964277267456055, 1.074308156967163, 1.2718411684036255, 1.288989543914795, 1.0767475366592407, 1.3088401556015015, 1.258864164352417]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8080
                    Iteration time: 1.21s
                        Total time: 94.73s
                               ETA: 937829.7s
################################################################################
                    [1m Learning iteration 101/1000000 
                       Computation: 59 steps/s (collection: 1.238s, learning 0.101s)
               Value function loss: 0.0005
                    Surrogate loss: 128.0744
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8222
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.21
     action noise std distribution: [1.0598446130752563, 1.2543377876281738, 1.3027209043502808, 1.065564751625061, 1.2671643495559692, 1.301378846168518, 1.075753927230835, 1.274565577507019, 1.2909601926803589, 1.0803552865982056, 1.3120949268341064, 1.2620769739151]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8160
                    Iteration time: 1.34s
                        Total time: 96.07s
                               ETA: 941751.7s
################################################################################
                    [1m Learning iteration 102/1000000 
                       Computation: 62 steps/s (collection: 1.173s, learning 0.100s)
               Value function loss: 0.0005
                    Surrogate loss: 918.9697
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8356
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.22
     action noise std distribution: [1.0640599727630615, 1.2570518255233765, 1.3051798343658447, 1.0683375597000122, 1.272379994392395, 1.3060426712036133, 1.0762654542922974, 1.2755132913589478, 1.2943276166915894, 1.0838927030563354, 1.3160587549209595, 1.2641184329986572]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8240
                    Iteration time: 1.27s
                        Total time: 97.34s
                               ETA: 944968.0s
################################################################################
                    [1m Learning iteration 103/1000000 
                       Computation: 64 steps/s (collection: 1.144s, learning 0.097s)
               Value function loss: 0.0004
                    Surrogate loss: 180.7900
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8765
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.22
     action noise std distribution: [1.0671266317367554, 1.2610806226730347, 1.3082820177078247, 1.0718538761138916, 1.2767553329467773, 1.3103101253509521, 1.078690767288208, 1.277969241142273, 1.2967935800552368, 1.0871647596359253, 1.3180361986160278, 1.2658425569534302]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8320
                    Iteration time: 1.24s
                        Total time: 98.58s
                               ETA: 947811.5s
################################################################################
                    [1m Learning iteration 104/1000000 
                       Computation: 62 steps/s (collection: 1.178s, learning 0.099s)
               Value function loss: 0.0005
                    Surrogate loss: 710.3944
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8770
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.22
     action noise std distribution: [1.0703905820846558, 1.265199065208435, 1.3100059032440186, 1.074992299079895, 1.2797778844833374, 1.3124949932098389, 1.0811169147491455, 1.2819982767105103, 1.3003290891647339, 1.0907626152038574, 1.3205918073654175, 1.2685521841049194]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8400
                    Iteration time: 1.28s
                        Total time: 99.86s
                               ETA: 950945.5s
################################################################################
                    [1m Learning iteration 105/1000000 
                       Computation: 63 steps/s (collection: 1.157s, learning 0.102s)
               Value function loss: 0.0004
                    Surrogate loss: 27.4475
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8791
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.22
     action noise std distribution: [1.072615146636963, 1.2688394784927368, 1.312080979347229, 1.0773301124572754, 1.282170295715332, 1.3153620958328247, 1.0839941501617432, 1.2850449085235596, 1.3031792640686035, 1.0928151607513428, 1.3232449293136597, 1.2688331604003906]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8480
                    Iteration time: 1.26s
                        Total time: 101.12s
                               ETA: 953854.2s
################################################################################
                    [1m Learning iteration 106/1000000 
                       Computation: 62 steps/s (collection: 1.183s, learning 0.097s)
               Value function loss: 0.0003
                    Surrogate loss: 14.7977
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.8961
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.23
     action noise std distribution: [1.0742820501327515, 1.2713125944137573, 1.3137444257736206, 1.0797054767608643, 1.2843223810195923, 1.3170247077941895, 1.085883617401123, 1.2880078554153442, 1.304152011871338, 1.0948699712753296, 1.3254073858261108, 1.2703293561935425]
                       Mean reward: 1.15
               Mean episode length: 1181.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0376
        Mean episode rew_lin_vel_z: -0.0485
        Mean episode rew_ang_vel_z: 0.1341
       Mean episode rew_ang_vel_xy: -0.0061
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3283
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8560
                    Iteration time: 1.28s
                        Total time: 102.40s
                               ETA: 956906.7s
################################################################################
                    [1m Learning iteration 107/1000000 
                       Computation: 61 steps/s (collection: 1.194s, learning 0.101s)
               Value function loss: 0.0211
                    Surrogate loss: 231.1842
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9814
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.23
     action noise std distribution: [1.0759422779083252, 1.275477647781372, 1.3169708251953125, 1.0822340250015259, 1.286149024963379, 1.3186969757080078, 1.0890165567398071, 1.2901875972747803, 1.306578516960144, 1.0963259935379028, 1.329568862915039, 1.2741923332214355]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.2928
        Mean episode rew_lin_vel_z: -0.0534
        Mean episode rew_ang_vel_z: 0.1978
       Mean episode rew_ang_vel_xy: -0.0081
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0189
        Mean episode rew_joint_acc: -0.0016
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3460
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8640
                    Iteration time: 1.29s
                        Total time: 103.69s
                               ETA: 960032.0s
################################################################################
                    [1m Learning iteration 108/1000000 
                       Computation: 64 steps/s (collection: 1.135s, learning 0.099s)
               Value function loss: 0.0021
                    Surrogate loss: 93.4273
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9324
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.23
     action noise std distribution: [1.080169916152954, 1.279673457145691, 1.3199633359909058, 1.085345983505249, 1.2884215116500854, 1.3223319053649902, 1.092941403388977, 1.2924188375473022, 1.3119165897369385, 1.0986242294311523, 1.3344300985336304, 1.278043508529663]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8720
                    Iteration time: 1.23s
                        Total time: 104.93s
                               ETA: 962546.9s
################################################################################
                    [1m Learning iteration 109/1000000 
                       Computation: 60 steps/s (collection: 1.215s, learning 0.099s)
               Value function loss: 0.0023
                    Surrogate loss: 241.4776
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9966
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.24
     action noise std distribution: [1.0858478546142578, 1.2822797298431396, 1.3237441778182983, 1.0901180505752563, 1.2925918102264404, 1.325533151626587, 1.0958870649337769, 1.295641541481018, 1.314757227897644, 1.1016932725906372, 1.3390344381332397, 1.2821208238601685]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8800
                    Iteration time: 1.31s
                        Total time: 106.24s
                               ETA: 965731.9s
################################################################################
                    [1m Learning iteration 110/1000000 
                       Computation: 61 steps/s (collection: 1.191s, learning 0.103s)
               Value function loss: 0.0010
                    Surrogate loss: 71.6588
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9995
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.24
     action noise std distribution: [1.0882117748260498, 1.2837806940078735, 1.3264613151550293, 1.0925670862197876, 1.296064019203186, 1.3280673027038574, 1.0979503393173218, 1.2990598678588867, 1.3173551559448242, 1.1059846878051758, 1.3433624505996704, 1.2862215042114258]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8880
                    Iteration time: 1.29s
                        Total time: 107.54s
                               ETA: 968687.0s
################################################################################
                    [1m Learning iteration 111/1000000 
                       Computation: 63 steps/s (collection: 1.152s, learning 0.100s)
               Value function loss: 0.0006
                    Surrogate loss: 63.5525
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 1.0329
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.24
     action noise std distribution: [1.089992642402649, 1.2868653535842896, 1.3304271697998047, 1.095056414604187, 1.29740309715271, 1.3291923999786377, 1.1003130674362183, 1.3023948669433594, 1.321280837059021, 1.1110159158706665, 1.3476474285125732, 1.2880922555923462]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8960
                    Iteration time: 1.25s
                        Total time: 108.79s
                               ETA: 971206.0s
################################################################################
                    [1m Learning iteration 112/1000000 
                       Computation: 61 steps/s (collection: 1.199s, learning 0.098s)
               Value function loss: 0.0007
                    Surrogate loss: 15.2328
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9996
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.24
     action noise std distribution: [1.094311237335205, 1.290911316871643, 1.334761619567871, 1.0989272594451904, 1.2985191345214844, 1.3310796022415161, 1.1018413305282593, 1.3051759004592896, 1.3259968757629395, 1.1156946420669556, 1.3498629331588745, 1.2904964685440063]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9040
                    Iteration time: 1.30s
                        Total time: 110.08s
                               ETA: 974090.7s
################################################################################
                    [1m Learning iteration 113/1000000 
                       Computation: 63 steps/s (collection: 1.150s, learning 0.106s)
               Value function loss: 0.0005
                    Surrogate loss: 578.7083
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9938
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.25
     action noise std distribution: [1.0979480743408203, 1.2957510948181152, 1.3379982709884644, 1.1011968851089478, 1.3010317087173462, 1.3324047327041626, 1.1049178838729858, 1.3089306354522705, 1.328376054763794, 1.1182876825332642, 1.3503669500350952, 1.2942265272140503]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9120
                    Iteration time: 1.26s
                        Total time: 111.34s
                               ETA: 976562.8s
################################################################################
                    [1m Learning iteration 114/1000000 
                       Computation: 63 steps/s (collection: 1.167s, learning 0.098s)
               Value function loss: 0.0005
                    Surrogate loss: 11.7668
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9841
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.25
     action noise std distribution: [1.101821780204773, 1.3006998300552368, 1.3426787853240967, 1.1039472818374634, 1.3045519590377808, 1.334231972694397, 1.1077265739440918, 1.312452793121338, 1.3318865299224854, 1.1216398477554321, 1.3529250621795654, 1.2966663837432861]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9200
                    Iteration time: 1.27s
                        Total time: 112.61s
                               ETA: 979071.6s
################################################################################
                    [1m Learning iteration 115/1000000 
                       Computation: 61 steps/s (collection: 1.196s, learning 0.099s)
               Value function loss: 0.0003
                    Surrogate loss: 31.6888
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9736
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.25
     action noise std distribution: [1.1045854091644287, 1.304796814918518, 1.3478000164031982, 1.1085878610610962, 1.3076996803283691, 1.337764024734497, 1.1100108623504639, 1.3154561519622803, 1.3354207277297974, 1.1235804557800293, 1.3570259809494019, 1.3008404970169067]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9280
                    Iteration time: 1.29s
                        Total time: 113.90s
                               ETA: 981790.1s
################################################################################
                    [1m Learning iteration 116/1000000 
                       Computation: 64 steps/s (collection: 1.136s, learning 0.100s)
               Value function loss: 0.0003
                    Surrogate loss: 49.5857
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 0.9724
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.26
     action noise std distribution: [1.1083970069885254, 1.3086233139038086, 1.3507721424102783, 1.1120725870132446, 1.3108444213867188, 1.3424670696258545, 1.1111152172088623, 1.319403052330017, 1.339289665222168, 1.126444697380066, 1.3579511642456055, 1.3042625188827515]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9360
                    Iteration time: 1.24s
                        Total time: 115.14s
                               ETA: 983966.3s
################################################################################
                    [1m Learning iteration 117/1000000 
                       Computation: 61 steps/s (collection: 1.192s, learning 0.100s)
               Value function loss: 0.0003
                    Surrogate loss: 55.0807
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 1.0042
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.26
     action noise std distribution: [1.1118874549865723, 1.3117005825042725, 1.3541351556777954, 1.1162327527999878, 1.3155782222747803, 1.3473362922668457, 1.1133677959442139, 1.3217816352844238, 1.3415499925613403, 1.129555344581604, 1.3610973358154297, 1.3073469400405884]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9440
                    Iteration time: 1.29s
                        Total time: 116.43s
                               ETA: 986578.8s
################################################################################
                    [1m Learning iteration 118/1000000 
                       Computation: 63 steps/s (collection: 1.159s, learning 0.101s)
               Value function loss: 0.0002
                    Surrogate loss: 2699.8227
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 1.0354
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.26
     action noise std distribution: [1.1140170097351074, 1.3151781558990479, 1.357535481452942, 1.1173688173294067, 1.3194096088409424, 1.350947618484497, 1.117214560508728, 1.3246465921401978, 1.3444023132324219, 1.1333873271942139, 1.365599513053894, 1.3113055229187012]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9520
                    Iteration time: 1.26s
                        Total time: 117.69s
                               ETA: 988869.7s
################################################################################
                    [1m Learning iteration 119/1000000 
                       Computation: 65 steps/s (collection: 1.128s, learning 0.098s)
               Value function loss: 0.0001
                    Surrogate loss: 69.0938
   History latent supervision loss: 1.1489
  Privileged info regularizer loss: 1.0135
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.27
     action noise std distribution: [1.1165094375610352, 1.3192840814590454, 1.3606733083724976, 1.118412971496582, 1.320992112159729, 1.353951096534729, 1.1208817958831787, 1.3271839618682861, 1.3475914001464844, 1.1371381282806396, 1.3700616359710693, 1.3149588108062744]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9600
                    Iteration time: 1.23s
                        Total time: 118.92s
                               ETA: 990844.4s
################################################################################
                    [1m Learning iteration 120/1000000 
                       Computation: 66 steps/s (collection: 1.138s, learning 0.057s)
               Value function loss: 0.0001
                    Surrogate loss: 69.0938
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 1.0135
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.27
     action noise std distribution: [1.1165094375610352, 1.3192840814590454, 1.3606733083724976, 1.118412971496582, 1.320992112159729, 1.353951096534729, 1.1208817958831787, 1.3271839618682861, 1.3475914001464844, 1.1371381282806396, 1.3700616359710693, 1.3149588108062744]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9680
                    Iteration time: 1.20s
                        Total time: 120.11s
                               ETA: 992533.7s
################################################################################
                    [1m Learning iteration 121/1000000 
                       Computation: 71 steps/s (collection: 1.021s, learning 0.101s)
               Value function loss: 0.0001
                    Surrogate loss: 634.6276
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5535
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.27
     action noise std distribution: [1.1164506673812866, 1.3244105577468872, 1.3627095222473145, 1.1193431615829468, 1.3247826099395752, 1.3568168878555298, 1.1230151653289795, 1.3308857679367065, 1.3499629497528076, 1.140264868736267, 1.3726239204406738, 1.318926215171814]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9760
                    Iteration time: 1.12s
                        Total time: 121.23s
                               ETA: 993591.5s
################################################################################
                    [1m Learning iteration 122/1000000 
                       Computation: 70 steps/s (collection: 1.033s, learning 0.101s)
               Value function loss: 0.0002
                    Surrogate loss: 233.7092
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5380
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.27
     action noise std distribution: [1.1176830530166626, 1.3273744583129883, 1.363520622253418, 1.1222869157791138, 1.3290703296661377, 1.3600960969924927, 1.1265161037445068, 1.33534574508667, 1.3530675172805786, 1.143846869468689, 1.3752151727676392, 1.3240063190460205]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9840
                    Iteration time: 1.13s
                        Total time: 122.37s
                               ETA: 994732.5s
################################################################################
                    [1m Learning iteration 123/1000000 
                       Computation: 70 steps/s (collection: 1.039s, learning 0.098s)
               Value function loss: 0.0001
                    Surrogate loss: 43.5756
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5388
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.28
     action noise std distribution: [1.1195309162139893, 1.330426812171936, 1.3655662536621094, 1.1253117322921753, 1.3333640098571777, 1.3607659339904785, 1.130793809890747, 1.340321660041809, 1.358574390411377, 1.1465036869049072, 1.3796782493591309, 1.3279684782028198]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9920
                    Iteration time: 1.14s
                        Total time: 123.50s
                               ETA: 995878.6s
################################################################################
                    [1m Learning iteration 124/1000000 
                       Computation: 68 steps/s (collection: 1.073s, learning 0.102s)
               Value function loss: 0.0001
                    Surrogate loss: 126.1840
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5331
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.28
     action noise std distribution: [1.121917724609375, 1.3319511413574219, 1.3688868284225464, 1.1288987398147583, 1.3367921113967896, 1.3635050058364868, 1.1345272064208984, 1.3457667827606201, 1.3644678592681885, 1.1477851867675781, 1.3849769830703735, 1.3318920135498047]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10000
                    Iteration time: 1.17s
                        Total time: 124.68s
                               ETA: 997306.3s
################################################################################
                    [1m Learning iteration 125/1000000 
                       Computation: 68 steps/s (collection: 1.071s, learning 0.101s)
               Value function loss: 0.0001
                    Surrogate loss: 208.9980
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5383
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.28
     action noise std distribution: [1.1255261898040771, 1.3334918022155762, 1.371153473854065, 1.130988359451294, 1.3413671255111694, 1.3670498132705688, 1.1387721300125122, 1.3501825332641602, 1.367392897605896, 1.1503586769104004, 1.3890734910964966, 1.3350712060928345]
                       Mean reward: 1.77
               Mean episode length: 1073.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.3897
        Mean episode rew_lin_vel_z: -0.0552
        Mean episode rew_ang_vel_z: 0.2219
       Mean episode rew_ang_vel_xy: -0.0089
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0192
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3528
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10080
                    Iteration time: 1.17s
                        Total time: 125.85s
                               ETA: 998690.1s
################################################################################
                    [1m Learning iteration 126/1000000 
                       Computation: 72 steps/s (collection: 1.007s, learning 0.101s)
               Value function loss: 0.0005
                    Surrogate loss: 9.5515
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.6313
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.29
     action noise std distribution: [1.1279237270355225, 1.3357809782028198, 1.3745287656784058, 1.1338422298431396, 1.3440946340560913, 1.3694208860397339, 1.1413971185684204, 1.3530380725860596, 1.3684368133544922, 1.1541657447814941, 1.3937431573867798, 1.3388242721557617]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10160
                    Iteration time: 1.11s
                        Total time: 126.96s
                               ETA: 999553.4s
################################################################################
                    [1m Learning iteration 127/1000000 
                       Computation: 70 steps/s (collection: 1.032s, learning 0.100s)
               Value function loss: 0.0003
                    Surrogate loss: 216.6916
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5795
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.29
     action noise std distribution: [1.1312538385391235, 1.339286208152771, 1.3787634372711182, 1.1381800174713135, 1.3458304405212402, 1.3722671270370483, 1.1444898843765259, 1.3565516471862793, 1.3693690299987793, 1.1575051546096802, 1.398124098777771, 1.3429346084594727]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10240
                    Iteration time: 1.13s
                        Total time: 128.09s
                               ETA: 1000588.1s
################################################################################
                    [1m Learning iteration 128/1000000 
                       Computation: 69 steps/s (collection: 1.056s, learning 0.099s)
               Value function loss: 0.0002
                    Surrogate loss: 58.6949
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5755
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.29
     action noise std distribution: [1.1356178522109985, 1.343164324760437, 1.381654143333435, 1.1418567895889282, 1.3499181270599365, 1.3748775720596313, 1.1481972932815552, 1.3608386516571045, 1.3720840215682983, 1.1586732864379883, 1.399113655090332, 1.3471356630325317]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10320
                    Iteration time: 1.15s
                        Total time: 129.25s
                               ETA: 1001782.2s
################################################################################
                    [1m Learning iteration 129/1000000 
                       Computation: 68 steps/s (collection: 1.066s, learning 0.098s)
               Value function loss: 0.0001
                    Surrogate loss: 89.8740
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5655
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.30
     action noise std distribution: [1.14069402217865, 1.347704529762268, 1.385788083076477, 1.1457020044326782, 1.3535622358322144, 1.3763067722320557, 1.151681900024414, 1.3642326593399048, 1.3745136260986328, 1.1614065170288086, 1.4018081426620483, 1.3495266437530518]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10400
                    Iteration time: 1.16s
                        Total time: 130.41s
                               ETA: 1003029.9s
################################################################################
                    [1m Learning iteration 130/1000000 
                       Computation: 70 steps/s (collection: 1.029s, learning 0.102s)
               Value function loss: 0.0001
                    Surrogate loss: 91.9104
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5658
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.30
     action noise std distribution: [1.1434887647628784, 1.3524705171585083, 1.3893777132034302, 1.1494065523147583, 1.3566635847091675, 1.3799995183944702, 1.1544502973556519, 1.3677390813827515, 1.376732587814331, 1.1652997732162476, 1.4068176746368408, 1.3520866632461548]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10480
                    Iteration time: 1.13s
                        Total time: 131.54s
                               ETA: 1004008.1s
################################################################################
                    [1m Learning iteration 131/1000000 
                       Computation: 70 steps/s (collection: 1.035s, learning 0.100s)
               Value function loss: 0.0001
                    Surrogate loss: 24.8958
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5849
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.30
     action noise std distribution: [1.1465522050857544, 1.3558346033096313, 1.3929246664047241, 1.1523211002349854, 1.358384132385254, 1.3839092254638672, 1.1556202173233032, 1.371403455734253, 1.3800053596496582, 1.1683075428009033, 1.411087155342102, 1.3552443981170654]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10560
                    Iteration time: 1.14s
                        Total time: 132.68s
                               ETA: 1005004.5s
################################################################################
                    [1m Learning iteration 132/1000000 
                       Computation: 70 steps/s (collection: 1.022s, learning 0.108s)
               Value function loss: 0.0001
                    Surrogate loss: 13.7639
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5738
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.31
     action noise std distribution: [1.1493350267410278, 1.3585630655288696, 1.3950425386428833, 1.156463623046875, 1.3620107173919678, 1.3886562585830688, 1.1581213474273682, 1.3745957612991333, 1.384791374206543, 1.1719046831130981, 1.4152371883392334, 1.3572906255722046]
                       Mean reward: 1.50
               Mean episode length: 1008.20
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0893
        Mean episode rew_lin_vel_z: -0.0554
        Mean episode rew_ang_vel_z: 0.1932
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3747
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10640
                    Iteration time: 1.13s
                        Total time: 133.81s
                               ETA: 1005941.5s
################################################################################
                    [1m Learning iteration 133/1000000 
                       Computation: 66 steps/s (collection: 1.100s, learning 0.100s)
               Value function loss: 0.0007
                    Surrogate loss: 10.3224
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.6142
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.31
     action noise std distribution: [1.1518396139144897, 1.3592981100082397, 1.3952937126159668, 1.1596957445144653, 1.365174412727356, 1.3931161165237427, 1.1624051332473755, 1.378901720046997, 1.3890166282653809, 1.175347089767456, 1.419120192527771, 1.358177900314331]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0810
        Mean episode rew_lin_vel_z: -0.0538
        Mean episode rew_ang_vel_z: 0.1742
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0151
        Mean episode rew_joint_acc: -0.0018
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.3482
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10720
                    Iteration time: 1.20s
                        Total time: 135.01s
                               ETA: 1007387.3s
################################################################################
                    [1m Learning iteration 134/1000000 
                       Computation: 69 steps/s (collection: 1.049s, learning 0.099s)
               Value function loss: 0.0001
                    Surrogate loss: 39.5943
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5593
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.31
     action noise std distribution: [1.1534814834594727, 1.3620624542236328, 1.3978512287139893, 1.1615911722183228, 1.3665693998336792, 1.3956258296966553, 1.1663883924484253, 1.3829295635223389, 1.3917332887649536, 1.1795345544815063, 1.4223134517669678, 1.3580007553100586]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10800
                    Iteration time: 1.15s
                        Total time: 136.16s
                               ETA: 1008423.9s
################################################################################
                    [1m Learning iteration 135/1000000 
                       Computation: 69 steps/s (collection: 1.042s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 111.6918
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5441
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.31
     action noise std distribution: [1.1564286947250366, 1.3654403686523438, 1.4011974334716797, 1.1640969514846802, 1.3696027994155884, 1.3993353843688965, 1.1692196130752563, 1.386467695236206, 1.3946744203567505, 1.1839789152145386, 1.4245291948318481, 1.3580222129821777]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10880
                    Iteration time: 1.14s
                        Total time: 137.30s
                               ETA: 1009410.7s
################################################################################
                    [1m Learning iteration 136/1000000 
                       Computation: 70 steps/s (collection: 1.037s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 80.1656
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5475
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.32
     action noise std distribution: [1.1591498851776123, 1.3678160905838013, 1.4054179191589355, 1.1682515144348145, 1.3731839656829834, 1.4027897119522095, 1.1739249229431152, 1.3872603178024292, 1.3966739177703857, 1.187692403793335, 1.4261633157730103, 1.3602993488311768]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10960
                    Iteration time: 1.13s
                        Total time: 138.43s
                               ETA: 1010324.2s
################################################################################
                    [1m Learning iteration 137/1000000 
                       Computation: 71 steps/s (collection: 1.027s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 1279.9847
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5570
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.32
     action noise std distribution: [1.163055181503296, 1.3709335327148438, 1.4085253477096558, 1.1714524030685425, 1.3765370845794678, 1.4052784442901611, 1.1782951354980469, 1.3870707750320435, 1.399094581604004, 1.191910743713379, 1.4291646480560303, 1.3628216981887817]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11040
                    Iteration time: 1.12s
                        Total time: 139.56s
                               ETA: 1011152.3s
################################################################################
                    [1m Learning iteration 138/1000000 
                       Computation: 67 steps/s (collection: 1.094s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 389.1478
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5705
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.32
     action noise std distribution: [1.1664769649505615, 1.3748340606689453, 1.410841703414917, 1.1735845804214478, 1.3804429769515991, 1.4090113639831543, 1.1810871362686157, 1.3891123533248901, 1.4007185697555542, 1.194289207458496, 1.4317286014556885, 1.3667049407958984]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11120
                    Iteration time: 1.19s
                        Total time: 140.75s
                               ETA: 1012463.0s
################################################################################
                    [1m Learning iteration 139/1000000 
                       Computation: 67 steps/s (collection: 1.091s, learning 0.099s)
               Value function loss: 0.0000
                    Surrogate loss: 169.1227
   History latent supervision loss: 0.7856
  Privileged info regularizer loss: 0.5874
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.33
     action noise std distribution: [1.1691335439682007, 1.3778223991394043, 1.4116250276565552, 1.177266001701355, 1.3837685585021973, 1.412048578262329, 1.1845272779464722, 1.39291250705719, 1.40401291847229, 1.1980140209197998, 1.4347281455993652, 1.370726466178894]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11200
                    Iteration time: 1.19s
                        Total time: 141.94s
                               ETA: 1013727.7s
################################################################################
                    [1m Learning iteration 140/1000000 
                       Computation: 72 steps/s (collection: 1.048s, learning 0.056s)
               Value function loss: 0.0000
                    Surrogate loss: 169.1227
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.5874
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.33
     action noise std distribution: [1.1691335439682007, 1.3778223991394043, 1.4116250276565552, 1.177266001701355, 1.3837685585021973, 1.412048578262329, 1.1845272779464722, 1.39291250705719, 1.40401291847229, 1.1980140209197998, 1.4347281455993652, 1.370726466178894]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11280
                    Iteration time: 1.10s
                        Total time: 143.05s
                               ETA: 1014366.5s
################################################################################
                    [1m Learning iteration 141/1000000 
                       Computation: 67 steps/s (collection: 1.080s, learning 0.102s)
               Value function loss: 0.0000
                    Surrogate loss: 31.0824
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2518
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.33
     action noise std distribution: [1.1719967126846313, 1.380266547203064, 1.4134106636047363, 1.1801692247390747, 1.387541651725769, 1.4160866737365723, 1.1887540817260742, 1.3962011337280273, 1.4079463481903076, 1.2004038095474243, 1.4376866817474365, 1.374208688735962]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11360
                    Iteration time: 1.18s
                        Total time: 144.23s
                               ETA: 1015545.0s
################################################################################
                    [1m Learning iteration 142/1000000 
                       Computation: 71 steps/s (collection: 1.021s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 51.4641
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2476
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.33
     action noise std distribution: [1.176329493522644, 1.3832976818084717, 1.414678692817688, 1.1820323467254639, 1.3923695087432861, 1.420270562171936, 1.1914993524551392, 1.397525429725647, 1.4084999561309814, 1.2022671699523926, 1.440840482711792, 1.3761759996414185]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11440
                    Iteration time: 1.12s
                        Total time: 145.34s
                               ETA: 1016254.0s
################################################################################
                    [1m Learning iteration 143/1000000 
                       Computation: 68 steps/s (collection: 1.071s, learning 0.097s)
               Value function loss: 0.0000
                    Surrogate loss: 1031.1948
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2734
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.34
     action noise std distribution: [1.180346131324768, 1.3865336179733276, 1.4166182279586792, 1.1848700046539307, 1.3970966339111328, 1.4232622385025024, 1.1943203210830688, 1.4006340503692627, 1.4099860191345215, 1.2036694288253784, 1.4447150230407715, 1.3788000345230103]
                       Mean reward: 1.37
               Mean episode length: 945.18
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0225
        Mean episode rew_lin_vel_z: -0.0420
        Mean episode rew_ang_vel_z: 0.0410
       Mean episode rew_ang_vel_xy: -0.0036
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0074
        Mean episode rew_joint_acc: -0.0009
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.1624
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11520
                    Iteration time: 1.17s
                        Total time: 146.51s
                               ETA: 1017306.7s
################################################################################
                    [1m Learning iteration 144/1000000 
                       Computation: 70 steps/s (collection: 1.035s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 59.8765
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.3414
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.34
     action noise std distribution: [1.1823920011520386, 1.3903923034667969, 1.419780969619751, 1.1880929470062256, 1.4006599187850952, 1.424923300743103, 1.1966553926467896, 1.4012099504470825, 1.413811206817627, 1.2068253755569458, 1.4482324123382568, 1.382291316986084]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0449
        Mean episode rew_lin_vel_z: -0.0445
        Mean episode rew_ang_vel_z: 0.0403
       Mean episode rew_ang_vel_xy: -0.0045
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0099
        Mean episode rew_joint_acc: -0.0012
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.2306
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11600
                    Iteration time: 1.13s
                        Total time: 147.65s
                               ETA: 1018115.3s
################################################################################
                    [1m Learning iteration 145/1000000 
                       Computation: 67 steps/s (collection: 1.087s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 99.0842
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.3713
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.34
     action noise std distribution: [1.1838274002075195, 1.3943551778793335, 1.423227310180664, 1.1923309564590454, 1.4026062488555908, 1.4262410402297974, 1.1967071294784546, 1.4035216569900513, 1.4176583290100098, 1.2102479934692383, 1.449705958366394, 1.3842238187789917]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11680
                    Iteration time: 1.19s
                        Total time: 148.84s
                               ETA: 1019275.6s
################################################################################
                    [1m Learning iteration 146/1000000 
                       Computation: 59 steps/s (collection: 1.246s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 419.2756
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2934
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.34
     action noise std distribution: [1.1860989332199097, 1.3990110158920288, 1.4266645908355713, 1.196816325187683, 1.4054628610610962, 1.4288372993469238, 1.1979883909225464, 1.4064639806747437, 1.4218535423278809, 1.2142738103866577, 1.450117826461792, 1.3876349925994873]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11760
                    Iteration time: 1.34s
                        Total time: 150.18s
                               ETA: 1021479.5s
################################################################################
                    [1m Learning iteration 147/1000000 
                       Computation: 69 steps/s (collection: 1.048s, learning 0.098s)
               Value function loss: 0.0000
                    Surrogate loss: 8289.3282
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2893
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.35
     action noise std distribution: [1.18867826461792, 1.402786135673523, 1.4308029413223267, 1.2007405757904053, 1.4092482328414917, 1.4319748878479004, 1.1992676258087158, 1.4082891941070557, 1.4264053106307983, 1.217078685760498, 1.453065037727356, 1.3922115564346313]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11840
                    Iteration time: 1.15s
                        Total time: 151.33s
                               ETA: 1022319.0s
################################################################################
                    [1m Learning iteration 148/1000000 
                       Computation: 67 steps/s (collection: 1.084s, learning 0.101s)
               Value function loss: 0.0000
                    Surrogate loss: 34.2411
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2638
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.35
     action noise std distribution: [1.1892083883285522, 1.4063414335250854, 1.434154987335205, 1.2022713422775269, 1.4111191034317017, 1.4354333877563477, 1.2001664638519287, 1.411128282546997, 1.4279299974441528, 1.2200671434402466, 1.4564146995544434, 1.3938605785369873]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11920
                    Iteration time: 1.18s
                        Total time: 152.51s
                               ETA: 1023404.7s
################################################################################
                    [1m Learning iteration 149/1000000 
                       Computation: 69 steps/s (collection: 1.055s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 315.4338
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2736
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.35
     action noise std distribution: [1.192293405532837, 1.4094486236572266, 1.4367492198944092, 1.203690767288208, 1.4140342473983765, 1.439051866531372, 1.2029672861099243, 1.4149770736694336, 1.4282766580581665, 1.222287893295288, 1.4607799053192139, 1.3954730033874512]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12000
                    Iteration time: 1.15s
                        Total time: 153.66s
                               ETA: 1024274.4s
################################################################################
                    [1m Learning iteration 150/1000000 
                       Computation: 56 steps/s (collection: 1.246s, learning 0.159s)
               Value function loss: 0.0000
                    Surrogate loss: 8.6740
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2434
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.35
     action noise std distribution: [1.1966447830200195, 1.4134677648544312, 1.4398527145385742, 1.2037931680679321, 1.4175764322280884, 1.4422097206115723, 1.2056529521942139, 1.418027639389038, 1.4289138317108154, 1.2246443033218384, 1.465041995048523, 1.3987421989440918]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12080
                    Iteration time: 1.40s
                        Total time: 155.07s
                               ETA: 1026789.3s
################################################################################
                    [1m Learning iteration 151/1000000 
                       Computation: 66 steps/s (collection: 1.104s, learning 0.100s)
               Value function loss: 0.0000
                    Surrogate loss: 250.5101
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2814
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.36
     action noise std distribution: [1.2001066207885742, 1.4163947105407715, 1.4432737827301025, 1.2057080268859863, 1.4220327138900757, 1.4459284543991089, 1.2071748971939087, 1.4185209274291992, 1.431294560432434, 1.2285399436950684, 1.4655077457427979, 1.4024620056152344]
                       Mean reward: 1.26
               Mean episode length: 928.83
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1038
        Mean episode rew_lin_vel_z: -0.0509
        Mean episode rew_ang_vel_z: 0.0384
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0165
        Mean episode rew_joint_acc: -0.0020
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4104
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12160
                    Iteration time: 1.20s
                        Total time: 156.27s
                               ETA: 1027949.0s
################################################################################
                    [1m Learning iteration 152/1000000 
                       Computation: 67 steps/s (collection: 1.082s, learning 0.100s)
               Value function loss: 0.0002
                    Surrogate loss: 710.9302
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.3818
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.36
     action noise std distribution: [1.2022359371185303, 1.4203816652297974, 1.446851134300232, 1.2096372842788696, 1.4256004095077515, 1.450190782546997, 1.2104783058166504, 1.4213312864303589, 1.4339197874069214, 1.232662558555603, 1.4660919904708862, 1.4060002565383911]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0756
        Mean episode rew_lin_vel_z: -0.0486
        Mean episode rew_ang_vel_z: 0.0317
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0164
        Mean episode rew_joint_acc: -0.0021
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4219
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12240
                    Iteration time: 1.18s
                        Total time: 157.45s
                               ETA: 1028948.5s
################################################################################
                    [1m Learning iteration 153/1000000 
                       Computation: 68 steps/s (collection: 1.064s, learning 0.098s)
               Value function loss: 0.0024
                    Surrogate loss: 21.8446
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.3689
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.36
     action noise std distribution: [1.2045906782150269, 1.425829291343689, 1.4507979154586792, 1.2122811079025269, 1.4297914505004883, 1.4539865255355835, 1.2143996953964233, 1.4254547357559204, 1.4372614622116089, 1.2343330383300781, 1.468165397644043, 1.4100184440612793]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12320
                    Iteration time: 1.16s
                        Total time: 158.62s
                               ETA: 1029811.0s
################################################################################
                    [1m Learning iteration 154/1000000 
                       Computation: 66 steps/s (collection: 1.108s, learning 0.102s)
               Value function loss: 0.0021
                    Surrogate loss: 148.3185
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.3287
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.37
     action noise std distribution: [1.2079225778579712, 1.4296324253082275, 1.4537725448608398, 1.2129104137420654, 1.4336543083190918, 1.4581166505813599, 1.2174869775772095, 1.4289759397506714, 1.4392250776290894, 1.2368263006210327, 1.4721589088439941, 1.414345622062683]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12400
                    Iteration time: 1.21s
                        Total time: 159.83s
                               ETA: 1030971.4s
################################################################################
                    [1m Learning iteration 155/1000000 
                       Computation: 67 steps/s (collection: 1.085s, learning 0.100s)
               Value function loss: 0.0029
                    Surrogate loss: 18.0374
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2724
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.37
     action noise std distribution: [1.2117161750793457, 1.4307940006256104, 1.4569308757781982, 1.213324785232544, 1.436872959136963, 1.4603255987167358, 1.2195162773132324, 1.4318182468414307, 1.4410622119903564, 1.238974690437317, 1.4765630960464478, 1.4190524816513062]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12480
                    Iteration time: 1.19s
                        Total time: 161.01s
                               ETA: 1031957.7s
################################################################################
                    [1m Learning iteration 156/1000000 
                       Computation: 66 steps/s (collection: 1.114s, learning 0.098s)
               Value function loss: 0.0018
                    Surrogate loss: 166.9150
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2720
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.37
     action noise std distribution: [1.2151750326156616, 1.4330265522003174, 1.4605685472488403, 1.2146837711334229, 1.4360815286636353, 1.4627928733825684, 1.2216778993606567, 1.435799241065979, 1.4444553852081299, 1.2417889833450317, 1.4795434474945068, 1.4219087362289429]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12560
                    Iteration time: 1.21s
                        Total time: 162.22s
                               ETA: 1033099.3s
################################################################################
                    [1m Learning iteration 157/1000000 
                       Computation: 70 steps/s (collection: 1.029s, learning 0.100s)
               Value function loss: 0.0030
                    Surrogate loss: 153.7547
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2717
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.38
     action noise std distribution: [1.2182319164276123, 1.4374363422393799, 1.464948296546936, 1.2152739763259888, 1.437549114227295, 1.466092824935913, 1.2239776849746704, 1.4380888938903809, 1.4482074975967407, 1.244753122329712, 1.483480453491211, 1.425166130065918]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12640
                    Iteration time: 1.13s
                        Total time: 163.35s
                               ETA: 1033702.4s
################################################################################
                    [1m Learning iteration 158/1000000 
                       Computation: 68 steps/s (collection: 1.058s, learning 0.102s)
               Value function loss: 0.0021
                    Surrogate loss: 106.8255
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2615
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.38
     action noise std distribution: [1.2217093706130981, 1.4424755573272705, 1.4676973819732666, 1.2157496213912964, 1.441766619682312, 1.4697139263153076, 1.2279951572418213, 1.4376952648162842, 1.4510438442230225, 1.2482998371124268, 1.4860011339187622, 1.4287173748016357]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12720
                    Iteration time: 1.16s
                        Total time: 164.51s
                               ETA: 1034497.9s
################################################################################
                    [1m Learning iteration 159/1000000 
                       Computation: 67 steps/s (collection: 1.083s, learning 0.099s)
               Value function loss: 0.0016
                    Surrogate loss: 66.3433
   History latent supervision loss: 0.4225
  Privileged info regularizer loss: 0.2713
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.38
     action noise std distribution: [1.2258999347686768, 1.447368860244751, 1.4682952165603638, 1.218446135520935, 1.4459798336029053, 1.4737820625305176, 1.232110857963562, 1.4399114847183228, 1.45303475856781, 1.2519183158874512, 1.4879776239395142, 1.4324454069137573]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12800
                    Iteration time: 1.18s
                        Total time: 165.69s
                               ETA: 1035415.2s
################################################################################
                    [1m Learning iteration 160/1000000 
                       Computation: 69 steps/s (collection: 1.089s, learning 0.057s)
               Value function loss: 0.0016
                    Surrogate loss: 66.3433
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2713
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.38
     action noise std distribution: [1.2258999347686768, 1.447368860244751, 1.4682952165603638, 1.218446135520935, 1.4459798336029053, 1.4737820625305176, 1.232110857963562, 1.4399114847183228, 1.45303475856781, 1.2519183158874512, 1.4879776239395142, 1.4324454069137573]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12880
                    Iteration time: 1.15s
                        Total time: 166.84s
                               ETA: 1036103.5s
################################################################################
                    [1m Learning iteration 161/1000000 
                       Computation: 64 steps/s (collection: 1.133s, learning 0.107s)
               Value function loss: 0.0015
                    Surrogate loss: 282.7524
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.1640
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.38
     action noise std distribution: [1.2294422388076782, 1.4496610164642334, 1.4705897569656372, 1.2227476835250854, 1.4498482942581177, 1.4780007600784302, 1.2358659505844116, 1.4434723854064941, 1.4532746076583862, 1.2556583881378174, 1.4890966415405273, 1.437449336051941]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12960
                    Iteration time: 1.24s
                        Total time: 168.08s
                               ETA: 1037359.3s
################################################################################
                    [1m Learning iteration 162/1000000 
                       Computation: 67 steps/s (collection: 1.094s, learning 0.099s)
               Value function loss: 0.0014
                    Surrogate loss: 55.0650
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.1550
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.39
     action noise std distribution: [1.2334856986999512, 1.4529321193695068, 1.4741263389587402, 1.2272450923919678, 1.4522963762283325, 1.482141375541687, 1.239863634109497, 1.446104884147644, 1.4554054737091064, 1.258144497871399, 1.491358995437622, 1.440495491027832]
                       Mean reward: 1.16
               Mean episode length: 915.00
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.0333
        Mean episode rew_lin_vel_z: -0.0452
        Mean episode rew_ang_vel_z: 0.0216
       Mean episode rew_ang_vel_xy: -0.0069
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0162
        Mean episode rew_joint_acc: -0.0024
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4393
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13040
                    Iteration time: 1.19s
                        Total time: 169.27s
                               ETA: 1038311.2s
################################################################################
                    [1m Learning iteration 163/1000000 
                       Computation: 63 steps/s (collection: 1.159s, learning 0.102s)
               Value function loss: 0.0016
                    Surrogate loss: 25.3940
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2885
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.39
     action noise std distribution: [1.2388253211975098, 1.456817388534546, 1.4759386777877808, 1.2303659915924072, 1.4537608623504639, 1.484926700592041, 1.242848515510559, 1.4495199918746948, 1.4577680826187134, 1.2612066268920898, 1.4949123859405518, 1.4411559104919434]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.0996
        Mean episode rew_lin_vel_z: -0.0503
        Mean episode rew_ang_vel_z: 0.0180
       Mean episode rew_ang_vel_xy: -0.0067
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0167
        Mean episode rew_joint_acc: -0.0023
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4443
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13120
                    Iteration time: 1.26s
                        Total time: 170.53s
                               ETA: 1039666.5s
################################################################################
                    [1m Learning iteration 164/1000000 
                       Computation: 60 steps/s (collection: 1.217s, learning 0.100s)
               Value function loss: 0.0032
                    Surrogate loss: 34.7282
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2657
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.39
     action noise std distribution: [1.2430371046066284, 1.459780216217041, 1.4777880907058716, 1.2332594394683838, 1.4565951824188232, 1.4885220527648926, 1.2459523677825928, 1.452674150466919, 1.4617383480072021, 1.2645610570907593, 1.4996370077133179, 1.4407655000686646]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13200
                    Iteration time: 1.32s
                        Total time: 171.85s
                               ETA: 1041344.2s
################################################################################
                    [1m Learning iteration 165/1000000 
                       Computation: 61 steps/s (collection: 1.203s, learning 0.098s)
               Value function loss: 0.0034
                    Surrogate loss: 85.6309
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2448
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.40
     action noise std distribution: [1.247523307800293, 1.4627455472946167, 1.4803287982940674, 1.235535740852356, 1.4613914489746094, 1.4920884370803833, 1.2500423192977905, 1.4539902210235596, 1.4628115892410278, 1.268532156944275, 1.5033589601516724, 1.4419785737991333]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13280
                    Iteration time: 1.30s
                        Total time: 173.15s
                               ETA: 1042908.5s
################################################################################
                    [1m Learning iteration 166/1000000 
                       Computation: 63 steps/s (collection: 1.161s, learning 0.099s)
               Value function loss: 0.0034
                    Surrogate loss: 14.0333
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2098
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.40
     action noise std distribution: [1.251368522644043, 1.4655755758285522, 1.4825401306152344, 1.2368651628494263, 1.4667631387710571, 1.4955289363861084, 1.2530866861343384, 1.4545962810516357, 1.4648233652114868, 1.2724627256393433, 1.5057413578033447, 1.4442099332809448]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13360
                    Iteration time: 1.26s
                        Total time: 174.41s
                               ETA: 1044204.0s
################################################################################
                    [1m Learning iteration 167/1000000 
                       Computation: 63 steps/s (collection: 1.159s, learning 0.101s)
               Value function loss: 0.0033
                    Surrogate loss: 816.3964
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2100
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.40
     action noise std distribution: [1.2542251348495483, 1.4689722061157227, 1.485026240348816, 1.2393155097961426, 1.470704197883606, 1.498892068862915, 1.2558636665344238, 1.4565694332122803, 1.4688345193862915, 1.2762024402618408, 1.5076911449432373, 1.4467735290527344]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13440
                    Iteration time: 1.26s
                        Total time: 175.67s
                               ETA: 1045482.7s
################################################################################
                    [1m Learning iteration 168/1000000 
                       Computation: 62 steps/s (collection: 1.188s, learning 0.098s)
               Value function loss: 0.0016
                    Surrogate loss: 44.7375
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2164
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.40
     action noise std distribution: [1.2564082145690918, 1.471679925918579, 1.4866069555282593, 1.2406412363052368, 1.4731777906417847, 1.5012849569320679, 1.2582560777664185, 1.4576854705810547, 1.4718161821365356, 1.2786669731140137, 1.5102605819702148, 1.4495199918746948]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13520
                    Iteration time: 1.29s
                        Total time: 176.96s
                               ETA: 1046905.4s
################################################################################
                    [1m Learning iteration 169/1000000 
                       Computation: 58 steps/s (collection: 1.269s, learning 0.099s)
               Value function loss: 0.0050
                    Surrogate loss: 45.0805
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.2423
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.41
     action noise std distribution: [1.256467580795288, 1.4755125045776367, 1.4888156652450562, 1.2435239553451538, 1.4746217727661133, 1.5044033527374268, 1.2610752582550049, 1.4584932327270508, 1.475080132484436, 1.2809960842132568, 1.5133250951766968, 1.4535013437271118]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13600
                    Iteration time: 1.37s
                        Total time: 178.32s
                               ETA: 1048791.1s
################################################################################
                    [1m Learning iteration 170/1000000 
                       Computation: 63 steps/s (collection: 1.161s, learning 0.098s)
               Value function loss: 0.0061
                    Surrogate loss: 253.5788
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3327
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.41
     action noise std distribution: [1.2581453323364258, 1.4788480997085571, 1.4910447597503662, 1.2463946342468262, 1.47576904296875, 1.5055263042449951, 1.2639703750610352, 1.4620999097824097, 1.4777802228927612, 1.2842704057693481, 1.5166854858398438, 1.456590175628662]
                       Mean reward: 1.08
               Mean episode length: 903.14
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1540
        Mean episode rew_lin_vel_z: -0.0544
        Mean episode rew_ang_vel_z: 0.0150
       Mean episode rew_ang_vel_xy: -0.0065
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0170
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4484
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13680
                    Iteration time: 1.26s
                        Total time: 179.58s
                               ETA: 1050021.7s
################################################################################
                    [1m Learning iteration 171/1000000 
                       Computation: 61 steps/s (collection: 1.204s, learning 0.103s)
               Value function loss: 0.0168
                    Surrogate loss: 25.5512
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.4680
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.41
     action noise std distribution: [1.2614672183990479, 1.4789137840270996, 1.493622064590454, 1.2471365928649902, 1.4737520217895508, 1.507544994354248, 1.2676162719726562, 1.4659042358398438, 1.480363368988037, 1.2840752601623535, 1.5177135467529297, 1.458443284034729]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.4270
        Mean episode rew_lin_vel_z: -0.0462
        Mean episode rew_ang_vel_z: 0.2845
       Mean episode rew_ang_vel_xy: -0.0081
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0177
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4630
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13760
                    Iteration time: 1.31s
                        Total time: 180.89s
                               ETA: 1051510.6s
################################################################################
                    [1m Learning iteration 172/1000000 
                       Computation: 60 steps/s (collection: 1.214s, learning 0.106s)
               Value function loss: 0.0016
                    Surrogate loss: 72.5646
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3125
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.41
     action noise std distribution: [1.2648581266403198, 1.479866623878479, 1.495912790298462, 1.2489646673202515, 1.4748883247375488, 1.5101771354675293, 1.272215723991394, 1.4694629907608032, 1.482747197151184, 1.2849578857421875, 1.520213007926941, 1.4616329669952393]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13840
                    Iteration time: 1.32s
                        Total time: 182.21s
                               ETA: 1053058.3s
################################################################################
                    [1m Learning iteration 173/1000000 
                       Computation: 61 steps/s (collection: 1.194s, learning 0.101s)
               Value function loss: 0.0007
                    Surrogate loss: 28.5740
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3934
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.42
     action noise std distribution: [1.2672488689422607, 1.482710361480713, 1.4981772899627686, 1.2514302730560303, 1.479425072669983, 1.513460397720337, 1.2745386362075806, 1.4725878238677979, 1.4844236373901367, 1.2882788181304932, 1.5249218940734863, 1.4645146131515503]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13920
                    Iteration time: 1.29s
                        Total time: 183.51s
                               ETA: 1054444.2s
################################################################################
                    [1m Learning iteration 174/1000000 
                       Computation: 62 steps/s (collection: 1.187s, learning 0.100s)
               Value function loss: 0.0004
                    Surrogate loss: 50.8886
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3352
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.42
     action noise std distribution: [1.2671711444854736, 1.485481858253479, 1.5014562606811523, 1.2538840770721436, 1.483789086341858, 1.5164364576339722, 1.2782695293426514, 1.4748353958129883, 1.4863412380218506, 1.2904841899871826, 1.528428316116333, 1.467374324798584]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14000
                    Iteration time: 1.29s
                        Total time: 184.79s
                               ETA: 1055766.7s
################################################################################
                    [1m Learning iteration 175/1000000 
                       Computation: 62 steps/s (collection: 1.171s, learning 0.104s)
               Value function loss: 0.0004
                    Surrogate loss: 151.0133
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3826
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.42
     action noise std distribution: [1.2670769691467285, 1.489297866821289, 1.504920244216919, 1.257620096206665, 1.4878700971603394, 1.5191832780838013, 1.2827523946762085, 1.4780629873275757, 1.489206075668335, 1.2912341356277466, 1.5311850309371948, 1.4691370725631714]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14080
                    Iteration time: 1.27s
                        Total time: 186.07s
                               ETA: 1057006.0s
################################################################################
                    [1m Learning iteration 176/1000000 
                       Computation: 61 steps/s (collection: 1.181s, learning 0.116s)
               Value function loss: 0.0003
                    Surrogate loss: 27.2240
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.3850
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.43
     action noise std distribution: [1.268854022026062, 1.49191415309906, 1.5084255933761597, 1.262896180152893, 1.4922116994857788, 1.5222759246826172, 1.2870404720306396, 1.4806989431381226, 1.4923884868621826, 1.2939893007278442, 1.5349568128585815, 1.471692681312561]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14160
                    Iteration time: 1.30s
                        Total time: 187.36s
                               ETA: 1058359.8s
################################################################################
                    [1m Learning iteration 177/1000000 
                       Computation: 53 steps/s (collection: 1.402s, learning 0.105s)
               Value function loss: 0.0004
                    Surrogate loss: 1926.6540
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.4858
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.43
     action noise std distribution: [1.2712998390197754, 1.4938669204711914, 1.5124218463897705, 1.2656997442245483, 1.4947353601455688, 1.524944543838501, 1.2904466390609741, 1.4839898347854614, 1.4973167181015015, 1.2963905334472656, 1.5380281209945679, 1.4755115509033203]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14240
                    Iteration time: 1.51s
                        Total time: 188.87s
                               ETA: 1060875.5s
################################################################################
                    [1m Learning iteration 178/1000000 
                       Computation: 62 steps/s (collection: 1.175s, learning 0.106s)
               Value function loss: 0.0002
                    Surrogate loss: 100.7434
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.4962
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.43
     action noise std distribution: [1.2743362188339233, 1.4968904256820679, 1.515051007270813, 1.2679619789123535, 1.4976985454559326, 1.5272341966629028, 1.2939085960388184, 1.4869904518127441, 1.5031108856201172, 1.2997716665267944, 1.54006826877594, 1.4787770509719849]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14320
                    Iteration time: 1.28s
                        Total time: 190.15s
                               ETA: 1062103.3s
################################################################################
                    [1m Learning iteration 179/1000000 
                       Computation: 68 steps/s (collection: 1.069s, learning 0.100s)
               Value function loss: 0.0002
                    Surrogate loss: 466.9253
   History latent supervision loss: 0.1984
  Privileged info regularizer loss: 0.5550
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.43
     action noise std distribution: [1.276940941810608, 1.5008940696716309, 1.5188697576522827, 1.2705092430114746, 1.5020862817764282, 1.5303410291671753, 1.2959624528884888, 1.4883842468261719, 1.5071300268173218, 1.302019476890564, 1.5424113273620605, 1.482158899307251]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 1.17s
                        Total time: 191.32s
                               ETA: 1062693.8s
################################################################################
                    [1m Learning iteration 180/1000000 
                       Computation: 70 steps/s (collection: 1.079s, learning 0.058s)
               Value function loss: 0.0002
                    Surrogate loss: 466.9253
   History latent supervision loss: 0.3606
  Privileged info regularizer loss: 0.5550
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.43
     action noise std distribution: [1.276940941810608, 1.5008940696716309, 1.5188697576522827, 1.2705092430114746, 1.5020862817764282, 1.5303410291671753, 1.2959624528884888, 1.4883842468261719, 1.5071300268173218, 1.302019476890564, 1.5424113273620605, 1.482158899307251]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14480
                    Iteration time: 1.14s
                        Total time: 192.46s
                               ETA: 1063105.5s
################################################################################
                    [1m Learning iteration 181/1000000 
                       Computation: 67 steps/s (collection: 1.070s, learning 0.110s)
               Value function loss: 0.0002
                    Surrogate loss: 43.1386
   History latent supervision loss: 0.3606
  Privileged info regularizer loss: 0.2422
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.44
     action noise std distribution: [1.2800500392913818, 1.504611849784851, 1.523726463317871, 1.2726668119430542, 1.5064383745193481, 1.5346102714538574, 1.2992593050003052, 1.490578532218933, 1.5105817317962646, 1.3052127361297607, 1.5452908277511597, 1.4854371547698975]
                       Mean reward: 1.47
               Mean episode length: 892.87
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.5584
        Mean episode rew_lin_vel_z: -0.0423
        Mean episode rew_ang_vel_z: 0.4143
       Mean episode rew_ang_vel_xy: -0.0088
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0180
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4700
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14560
                    Iteration time: 1.18s
                        Total time: 193.64s
                               ETA: 1063741.3s
################################################################################
                    [1m Learning iteration 182/1000000 
                       Computation: 65 steps/s (collection: 1.114s, learning 0.105s)
               Value function loss: 0.0008
                    Surrogate loss: 240.2129
   History latent supervision loss: 0.3606
  Privileged info regularizer loss: 0.3745
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.44
     action noise std distribution: [1.2836817502975464, 1.5065346956253052, 1.527846336364746, 1.2756614685058594, 1.5104058980941772, 1.5380029678344727, 1.3015660047531128, 1.4936251640319824, 1.5112425088882446, 1.3089325428009033, 1.5487658977508545, 1.489297866821289]
                       Mean reward: 1.38
               Mean episode length: 883.88
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.2096
        Mean episode rew_lin_vel_z: -0.0586
        Mean episode rew_ang_vel_z: 0.0914
       Mean episode rew_ang_vel_xy: -0.0091
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0198
        Mean episode rew_joint_acc: -0.0022
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4698
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14640
                    Iteration time: 1.22s
                        Total time: 194.85s
                               ETA: 1064587.5s
################################################################################
                    [1m Learning iteration 183/1000000 
                       Computation: 61 steps/s (collection: 1.192s, learning 0.106s)
               Value function loss: 0.0007
                    Surrogate loss: 119.6251
   History latent supervision loss: 0.3606
  Privileged info regularizer loss: 0.2987
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.44
     action noise std distribution: [1.2860267162322998, 1.5090049505233765, 1.530603051185608, 1.2778539657592773, 1.5138479471206665, 1.5423738956451416, 1.302626132965088, 1.497094988822937, 1.5100228786468506, 1.3130955696105957, 1.5518991947174072, 1.493880033493042]
                       Mean reward: 1.38
               Mean episode length: 883.88
                             Dones: 0.01
       Mean episode rew_lin_vel_xy: 0.1356
        Mean episode rew_lin_vel_z: -0.0621
        Mean episode rew_ang_vel_z: 0.0230
       Mean episode rew_ang_vel_xy: -0.0091
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0201
        Mean episode rew_joint_acc: -0.0021
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4697
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14720
                    Iteration time: 1.30s
                        Total time: 196.15s
                               ETA: 1065854.1s
################################################################################
                    [1m Learning iteration 184/1000000 
                       Computation: 70 steps/s (collection: 1.038s, learning 0.099s)
               Value function loss: 0.0006
                    Surrogate loss: 277.6053
   History latent supervision loss: 0.3606
  Privileged info regularizer loss: 0.3096
Privileged info regularizer lambda: 0.0000
         Leg mean action noise std: 1.45
     action noise std distribution: [1.2892431020736694, 1.5091325044631958, 1.5327179431915283, 1.2793571949005127, 1.5159629583358765, 1.5456993579864502, 1.3063433170318604, 1.5004299879074097, 1.5116050243377686, 1.3163124322891235, 1.5550717115402222, 1.4975847005844116]
                       Mean reward: 1.38
               Mean episode length: 883.88
                             Dones: 0.00
       Mean episode rew_lin_vel_xy: 0.1356
        Mean episode rew_lin_vel_z: -0.0621
        Mean episode rew_ang_vel_z: 0.0230
       Mean episode rew_ang_vel_xy: -0.0091
           Mean episode rew_orient: 0.0000
          Mean episode rew_torques: -0.0201
        Mean episode rew_joint_acc: -0.0021
      Mean episode rew_base_height: 0.0000
         Mean episode rew_air_time: 0.0000
        Mean episode rew_collision: 0.0000
          Mean episode rew_stumble: 0.0000
      Mean episode rew_action_rate: -0.4697
              Mean episode rew_hip: 0.0000
        Mean episode terrain_level: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14800
                    Iteration time: 1.14s
                        Total time: 197.29s
